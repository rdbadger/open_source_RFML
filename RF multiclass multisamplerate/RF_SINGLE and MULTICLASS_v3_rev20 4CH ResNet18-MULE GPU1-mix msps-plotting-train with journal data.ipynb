{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn5_7mqggh2H"
   },
   "source": [
    "## sigMF RF single and multi-classification; 12 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added multiclass function for dividing batches for mixing to create 1, 2 or 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2251,
     "status": "ok",
     "timestamp": 1548951950015,
     "user": {
      "displayName": "Robert Badger",
      "photoUrl": "",
      "userId": "11966704463856227449"
     },
     "user_tz": 300
    },
    "id": "r80FflgHhCiH",
    "outputId": "143411b2-cc11-47a1-c334-a76291219798",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version = 1.6.0 CUDA version = 10.2\n",
      "CUDA Device: cuda:1\n",
      "Is cuda available? = True\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "# import posixpath\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import glob\n",
    "import json\n",
    "from os import walk\n",
    "import pickle\n",
    "import json\n",
    "import pathlib\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "global GPU, fft, Fs, center_freq, fft_val, Fs_test, loss, batches, eps, var_noise, mean_noise, top\n",
    "global c1_coeff, c2_coeff, a, r1_c1, r2_c1, r1_c2, r2_c2, compare\n",
    "a = 1\n",
    "compare = .5\n",
    "r1_c2 = 1\n",
    "r2_c2 = 20e0\n",
    "top = .975\n",
    "var_noise = 8.78e-09\n",
    "# mean_noise = 10 # worked pretty good\n",
    "mean_noise = 1\n",
    "eps = 1e-15\n",
    "Fs = 1000000\n",
    "fft = 1024\n",
    "center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz\n",
    "center_freq_live = 428.00e6 # when SDR doing 25MSPS with center at 428MHz\n",
    "# batches = 128\n",
    "plt.style.use('default')\n",
    "GPU = 1\n",
    "cuda = \"cuda:1\"\n",
    "device = torch.device(cuda)\n",
    "print('Torch version =', torch.__version__, 'CUDA version =', torch.version.cuda)\n",
    "print('CUDA Device:', device)\n",
    "print('Is cuda available? =',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!. /home/david/prefix-3.8/setup_env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t_9_D3l0Px9"
   },
   "source": [
    "#### Machine paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = \"/media/david/Elements/sigMF_ML/RF/RF_class/data/\" # path to external drive\n",
    "path = \"/media/david/Extreme Pro/data/combined_data/training_data/\" # path to external drive\n",
    "path_ram = \"/home/david/sigMF_ML/RF/ramdisk/\"\n",
    "path_usrp = \"/home/david/prefix-3.8/\"\n",
    "# path_1msps = \"/home/david/sigMF_ML/RF/RF_class/data_1msps/\" # ACE\n",
    "# path_25msps = \"/home/david/sigMF_ML/RF/RF_class/data_25msps/\" # ACE\n",
    "path_1msps = \"/media/david/Extreme Pro/data/seperate_data/data_1msps/\" # External extreme drive\n",
    "path_25msps = \"/media/david/Extreme Pro/data/seperate_data/data_25msps/\" # External extreme drive\n",
    "path_fig = \"/home/david/sigMF_ML/RF/RF_class/figures/\" # ACE\n",
    "path_val = \"/home/david/sigMF_ML/RF/RF_class/testing_data/\" # ACE\n",
    "path_save = \"/home/david/sigMF_ML/RF/RF_class/saved/\" # ACE\n",
    "path_save2 = \"/media/david/Elements/saved/20220210_mix_2classes/\" # external elements drive\n",
    "path_save3 = \"/media/david/Elements/saved/20220210_mix_3classes/\" # external elements drive\n",
    "path_save_resnet18 = \"/media/david/Elements/saved/20220226_mix_1classes/\" # external elements drive\n",
    "path_test = \"/home/david/sigMF_ML/RF/RF_class/testing_data/\" # ACE\n",
    "path_test_1msps = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_1msps/\" # external drive\n",
    "path_test_5msps = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_5msps/\" # external drive\n",
    "path_test_10msps = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_10msps/\" # external drive\n",
    "path_test_25msps = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_25msps/\" # external drive\n",
    "# path_test_1msps = \"/home/david/sigMF_ML/RF/RF_class/testing_data_1msps/\" # ACE\n",
    "# path_test_5msps = \"/home/david/sigMF_ML/RF/RF_class/testing_data_5msps/\" # ACE\n",
    "# path_test_10msps = \"/home/david/sigMF_ML/RF/RF_class/testing_data_10msps/\" # ACE\n",
    "# path_test_25msps = \"/home/david/sigMF_ML/RF/RF_class/testing_data_25msps/\" # ACE\n",
    "path_validation = \"/home/david/sigMF_ML/RF/RF_class/validation/\" # multiclass validation\n",
    "path_val_1msps = \"/home/david/sigMF_ML/RF/RF_class/val_1msps/\" # multiclass validation\n",
    "path_val_5msps = \"/home/david/sigMF_ML/RF/RF_class/val_5msps/\" # multiclass validation\n",
    "path_val_10msps = \"/home/david/sigMF_ML/RF/RF_class/val_10msps/\" # multiclass validation\n",
    "path_val_25msps = \"/home/david/sigMF_ML/RF/RF_class/val_25msps/\" # multiclass validation\n",
    "# print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_test)\n",
    "\n",
    "os.chdir(path_test)\n",
    "data_files_test = sorted(glob.glob('*.sigmf-data'))\n",
    "meta_files_test = sorted(glob.glob('*.sigmf-meta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF FUNCTIONS ****************************************************\n",
    "def meta_encoder(meta_list, num_classes): \n",
    "    a = np.asarray(meta_list, dtype=int)\n",
    "#    print('a = ', a)\n",
    "    return a \n",
    "\n",
    "def save_model(epoch, loss, iter_batch):\n",
    "    rf_model = 'ResNet18_multiclass_20220226_mix_autosave_GPU1_1class'\n",
    "    PATH = path_save_resnet18+rf_model\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,}, PATH+'_train-epoch-{}-batch-{}.pt'.format(epoch, iter_batch)) \n",
    "    \n",
    "    torch.save(model.state_dict(), PATH+'_inference-epoch-{}-batch-{}.pt'.format(epoch, iter_batch))\n",
    "    \n",
    "# def load_model():\n",
    "#     rf_model = 'ResNet50_20210405_autosave'\n",
    "#     PATH = path_save+rf_model\n",
    "#     device = torch.device(\"cuda:0\")\n",
    "#     model = resnet50(4, 12)\n",
    "#     model.load_state_dict(torch.load(PATH))\n",
    "#     model.to(device)\n",
    "#     model.train() \n",
    "#     return model\n",
    "\n",
    "def load_model():\n",
    "    rf_model = 'ResNet50_multiclass_20211212_autosave_GPU0'\n",
    "    PATH = path_save+rf_model\n",
    "    device = torch.device(cuda)\n",
    "    model = resnet50(4, 12)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    model.to(device)\n",
    "    model.train() \n",
    "    return model, optimizer\n",
    "\n",
    "def load_model2(rf_model):\n",
    "#     rf_model = 'ResNet50_v58_20210212_4D_autosave'\n",
    "    PATH = path_save+rf_model\n",
    "    device = torch.device(cuda)\n",
    "#     model = resnet50(4, 12)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_original():\n",
    "    rf_model = 'ResNet50_20210430_mix2_score'\n",
    "    PATH = path_save+rf_model\n",
    "    device = torch.device(cuda)\n",
    "#     model = resnet50(4, 12)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "\n",
    "def gpu_test_file(db,msps): # THIS IS ACTUALLY USED FOR LIVE TESTING\n",
    "    if (msps == 1):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 5):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 10):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 25):\n",
    "        w1 = fft*msps\n",
    "#     print('gpu_test file function')    \n",
    "    I = db[0::2]\n",
    "    Q = db[1::2]\n",
    "    w = fft*msps\n",
    "#     print('Sample Rate = ',w,'MSPS')\n",
    "    den = 2\n",
    "#     print('window length = ', w1)\n",
    "    win = torch.hamming_window(w1, periodic=True, dtype=None, layout=torch.strided, requires_grad=False).cuda(GPU)\n",
    "    I_stft = torch.stft(torch.tensor(I).cuda(GPU), n_fft=w, hop_length=w//den, win_length=w1, window=win, center=True, normalized=True, onesided=False)\n",
    "    Q_stft = torch.stft(torch.tensor(Q).cuda(GPU), n_fft=w, hop_length=w//den, win_length=w1, window=win, center=True, normalized=True, onesided=False)\n",
    "    X_stft = I_stft[...,0] + Q_stft[...,0] + I_stft[...,1] + -1*Q_stft[...,1]\n",
    "#     print('X shape =', X_stft.shape)\n",
    "#     print('I shape =', I_stft.shape, 'Q shape = ', Q_stft.shape )\n",
    "    Z_stft = torch.cat((I_stft,Q_stft),2)\n",
    "#     print('Before: Final gpu_test file Z shape =', Z_stft.shape)\n",
    "#     Z_stft = torch.cat((Z_stft[w//2:,:,:],Z_stft[:w//2,:,:])) # NOT SURE I NEED TO DO THIS...\n",
    "#     print('After: Final gpu_test file Z shape =', Z_stft.shape)\n",
    "    Z_stft = Z_stft[:w//2,:,:] # throw bottom 1/2 away\n",
    "#     print('FINAL Z shape =', Z_stft.shape)\n",
    "    torch.cuda.empty_cache()\n",
    "    return Z_stft # Returning 4D\n",
    "\n",
    "def gpu_test_live(db,msps):\n",
    "#     I = db[0:10000000:2]\n",
    "#     Q = db[1:10000000:2]      \n",
    "    print('gpu_test live function')    \n",
    "    if (msps == 1):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 5):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 10):\n",
    "        w1 = fft*msps\n",
    "    elif (msps == 25):\n",
    "        w1 = fft*msps     \n",
    "    I = db[0::2]\n",
    "    Q = db[1::2]\n",
    "    w = fft*msps\n",
    "    print('Sample Rate = ',w,'MSPS')\n",
    "    den = 2\n",
    "    win = torch.hann_window(w1, periodic=True, dtype=None, layout=torch.strided, requires_grad=False).cuda(GPU)\n",
    "    I_stft = torch.stft(torch.tensor(I).cuda(GPU), n_fft=w, hop_length=w//den, win_length=w1, window=win, center=True, normalized=True, onesided=True)\n",
    "    Q_stft = torch.stft(torch.tensor(Q).cuda(GPU), n_fft=w, hop_length=w//den, win_length=w1, window=win, center=True, normalized=True, onesided=True)\n",
    "    Z_stft = torch.cat((I_stft,Q_stft),2)\n",
    "#     print('gpu_test live IQ shape =', Z_stft.shape)\n",
    "    Z_stft = torch.cat((Z_stft[w//2:,:,:],Z_stft[:w//2,:,:])) # NOT SURE I NEED TO DO THIS...\n",
    "    Z_stft = Z_stft[10:w//2,:,:]# throw bottom 1/2 away\n",
    "    print('FINAL gpu_test LIVE IQ shape =', Z_stft.shape)\n",
    "    torch.cuda.empty_cache()\n",
    "    return Z_stft # Returning 4D and plot\n",
    "\n",
    "def iq_read(data_files): # USING GPU to perform STFT\n",
    "    print('iq_read function**********')\n",
    "    data_IQ_list = []\n",
    "    data_IQ_temp = []\n",
    "    for file in data_files:\n",
    "        db = np.fromfile(file, dtype=\"float32\")\n",
    "#         stft = gpu(db).detach().cpu().numpy()\n",
    "        print('iq_read function')\n",
    "        stft, stft_plot = gpu_test_file(db)\n",
    "        stft = stft.detach().cpu().numpy()\n",
    "        stft_plot = stft_plot.detach().cpu().numpy()\n",
    "        stft_plot = 10*np.log10(np.abs(stft_plot+eps))\n",
    "        plt.imshow(stft_plot)\n",
    "        plt.pcolormesh(stft_plot)\n",
    "#         plt.imshow(stft, aspect='auto', origin='lower')\n",
    "        plt.show()\n",
    "        data_IQ_temp.append(stft)\n",
    "    data_IQ_list = np.array(data_IQ_temp)\n",
    "    return data_IQ_list\n",
    "\n",
    "def iq_read_test_file(data_files,msps): # USING GPU to perform STFT\n",
    "    data_IQ_list = []\n",
    "    data_IQ_temp = []\n",
    "    print('iq_read_test file')\n",
    "    for file in data_files:\n",
    "        db = np.fromfile(file, dtype=\"float32\")\n",
    "        stft = gpu_test_file(db,msps)\n",
    "        X_stft = stft[...,0] + stft[...,1] + stft[...,2] - stft[...,3]\n",
    "        stft_plot = 20*np.log10(np.abs(X_stft.detach().cpu().numpy()+eps))\n",
    "        print('imshow method')\n",
    "        plt.imshow(stft_plot, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "        plt.show()\n",
    "        data_IQ_temp.append(stft.detach().cpu().numpy())\n",
    "    data_IQ_list = np.array(data_IQ_temp)\n",
    "    return data_IQ_list\n",
    "\n",
    "def iq_read_test_live_old(data_files,msps): # USING GPU to perform STFT\n",
    "#     iq_cpu_plot(data_files) #checking with cpu complex plotting\n",
    "    data_IQ_list = []\n",
    "    data_IQ_temp = []\n",
    "    print('iq_read_test live: remarked out plotting')\n",
    "    for file in data_files:\n",
    "        db = np.fromfile(file, dtype=\"float32\")\n",
    "        stft = gpu_test_live(db,msps)\n",
    "        # *************************************************************************\n",
    "        X_stft = stft[...,0] + stft[...,1] + stft[...,2] - stft[...,3]\n",
    "        stft_plot = 20*np.log10(np.abs(X_stft.detach().cpu().numpy()+eps))       \n",
    "        print('iq_read_test live imshow method')\n",
    "        plt.imshow(stft_plot, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "        plt.show()\n",
    "        # *************************************************************************\n",
    "        data_IQ_temp.append(stft.detach().cpu().numpy())\n",
    "    data_IQ_list = np.array(data_IQ_temp)\n",
    "    return data_IQ_list\n",
    "\n",
    "def iq_read_test_live(data_files,msps): # 20210611 memory saver update\n",
    "    print('iq_read_test_live')\n",
    "#     print('file is =', data_files, type(data_files))\n",
    "    for file in data_files:\n",
    "        db = np.fromfile(file, dtype=\"float32\")\n",
    "        print('db = ', db.shape)\n",
    "    #     stft = gpu_test_file(db,msps).detach().cpu().numpy()\n",
    "        stft = gpu_test_file(db,msps)\n",
    "        X_stft = stft[...,0] + stft[...,1] + stft[...,2] - stft[...,3]\n",
    "        stft_plot = 20*np.log10(np.abs(X_stft.detach().cpu().numpy()+eps))\n",
    "        print('imshow method')\n",
    "        plt.imshow(stft_plot, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "        plt.show()\n",
    "    #     data_IQ_temp.append(stft.detach().cpu().numpy())\n",
    "    return stft\n",
    "\n",
    "def iq_read_test_live_combine(data_files,msps): # 20211025 memory saver update\n",
    "#     print('iq_read_test_live combined')\n",
    "#     print('file is =', data_files, type(data_files))\n",
    "    if msps==1:\n",
    "        db = np.zeros(20000000)\n",
    "    if msps==5:\n",
    "        db = np.zeros(50000000)  # 49999996  \n",
    "    if msps==10:\n",
    "        db = np.zeros(100000000)\n",
    "    elif msps==25:\n",
    "        db = np.zeros(250000000)    \n",
    "    for file in data_files:\n",
    "        temp = np.fromfile(file, dtype=\"float32\")\n",
    "#         print('read file shape = ', temp.shape)\n",
    "        if (len(db) > len(temp)):\n",
    "            N = np.abs(len(db)-len(temp))\n",
    "#             print('N = ', N)\n",
    "            temp = np.pad(temp, (0, N), 'constant')\n",
    "#             print('new file length = ', len(temp))\n",
    "        db = db + temp\n",
    "#         print('db = ', db.shape)\n",
    "    #     stft = gpu_test_file(db,msps).detach().cpu().numpy()\n",
    "    stft = gpu_test_file(db,msps)\n",
    "#     X_stft = stft[...,0] + stft[...,1] + stft[...,2] - stft[...,3]\n",
    "#     stft_plot = 20*np.log10(np.abs(X_stft.detach().cpu().numpy()+eps))\n",
    "#     print('imshow method')\n",
    "#     plt.imshow(stft_plot, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "#     plt.show()\n",
    "    #     data_IQ_temp.append(stft.detach().cpu().numpy())\n",
    "    return stft\n",
    "\n",
    "def read_meta(meta_files):\n",
    "    meta_list = []\n",
    "    for meta in meta_files:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        meta_list.append(all_meta_data['global'][\"core:class\"])\n",
    "    meta_list = list(map(int, meta_list))\n",
    "    return meta_list\n",
    "\n",
    "def read_num_val(x):\n",
    "    x = len(meta_list_val)\n",
    "    return x\n",
    "\n",
    "#**************************** Print historgram subplots ******************************\n",
    "def histo_plots(inputs):\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    ncols = 2\n",
    "    nrows = 2\n",
    "    print('make torch inputs')\n",
    "    print('inputs shape for histogram1 = ', inputs.shape)\n",
    "    inputs = 10*np.log10(np.abs(inputs.cpu()+eps))\n",
    "    for x in range(4):\n",
    "#         print('x = ', x, 'inputs shape for histogram2 = ', inputs[:,:,x].shape)\n",
    "        flat_inputs = torch.flatten(inputs[:,:,x], start_dim=0, end_dim=-1).numpy()\n",
    "#         print('type = ', type(flat_inputs))\n",
    "#         print('x = ', x, 'flat_input max = ', np.amax(flat_inputs))\n",
    "#         print('inputs are: ', flat_inputs.shape)\n",
    "        fig.add_subplot(nrows, ncols, x+1)\n",
    "        plt.hist(flat_inputs, bins=5000)\n",
    "        plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "        plt.xlim(-100, 10)\n",
    "#         plt.ylim(0, 40000)\n",
    "    return flat_inputs\n",
    "#*************************************************************************************    \n",
    "#**************************** Print historgram subplots ******************************\n",
    "def histo_stats(inputs):\n",
    "#     print('make torch inputs')\n",
    "#     print('inputs shape for histogram1 = ', inputs.shape)\n",
    "    mean = np.zeros(4)\n",
    "    std = np.zeros(4)\n",
    "    for x in range(4):\n",
    "#         print('x = ', x, 'inputs shape for histogram2 = ', inputs[:,:,x].shape)\n",
    "        flat_inputs = torch.flatten(inputs[:,:,x], start_dim=0, end_dim=-1).numpy()\n",
    "#         print('inputs are: ', flat_inputs.shape)\n",
    "        mean[x] = flat_inputs.mean()\n",
    "        std[x] = flat_inputs.std()\n",
    "#         print('mean = ', mean, 'std = ', std)\n",
    "    return mean, std\n",
    "#**************************** Print historgram freq stats ******************************\n",
    "def histo_stats_freq_file(inputs,msps):\n",
    "    mean = inputs.mean()\n",
    "    std = inputs.std()\n",
    "    print(\"mean Freq = {0:9,.2f}\".format(mean))\n",
    "    print(\"std Freq = {0:9,.2f}\".format(std))\n",
    "    print('length of inputs = ', len(inputs))\n",
    "#     plt.hist(inputs, 30, facecolor='blue', align='mid')\n",
    "    if (msps==25):\n",
    "        plt.hist(inputs, 30, range=[428.0, 440.0], facecolor='blue', align='mid')\n",
    "    elif (msps==1):\n",
    "        plt.hist(inputs, 30, range=[433.65, 434.15], facecolor='blue', align='mid')\n",
    "    elif (msps==5):\n",
    "        plt.hist(inputs, 30, range=[433.00, 435.50], facecolor='blue', align='mid')         \n",
    "    elif (msps==10):\n",
    "        plt.hist(inputs, 30, range=[433.00, 438.00], facecolor='blue', align='mid')        \n",
    "    else:\n",
    "        print('WRONG SAMPLE RATE CHOSEN')\n",
    "    plt.gca().set(title='Frequency Histogram', ylabel='Frequency'); \n",
    "    plt.show()\n",
    "def histo_stats_freq_live(inputs,msps):\n",
    "    mean = inputs.mean()\n",
    "    std = inputs.std()\n",
    "    print(\"mean Freq = {0:9,.2f}\".format(mean))\n",
    "    print(\"std Freq = {0:9,.2f}\".format(std))\n",
    "    print('length of inputs = ', len(inputs))\n",
    "#     plt.hist(inputs, 30, facecolor='blue', align='mid')\n",
    "    if (msps==25):\n",
    "        plt.hist(inputs, 30, range=[428.0, 440.0], facecolor='blue', align='mid')\n",
    "    elif (msps==1):\n",
    "        plt.hist(inputs, 30, range=[433.65, 434.15], facecolor='blue', align='mid')\n",
    "    elif (msps==5):\n",
    "        plt.hist(inputs, 30, range=[433.00, 435.50], facecolor='blue', align='mid')          \n",
    "    elif (msps==10):\n",
    "        plt.hist(inputs, 30, range=[433.00, 438.00], facecolor='blue', align='mid')         \n",
    "    else:\n",
    "        print('WRONG SAMPLE RATE CHOSEN')\n",
    "    plt.gca().set(title='Frequency Histogram', ylabel='Frequency'); \n",
    "    plt.show()\n",
    "# END OF FUNCTIONS ******************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start of ResNet blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
    "            \n",
    "        })) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
    "                          'bn': nn.BatchNorm2d(out_channels) }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet encoder composed by increasing different layers with increasing features.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,  *args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid() # added ~david\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x) # Logits output\n",
    "        y = self.sigmoid(x) # Added sigmoid function ~david\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
    "\n",
    "def resnet34(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet50(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet101(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
    "\n",
    "def resnet152(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of ResNet blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# model = resnet50(4, 12)\n",
    "# summary(model.cuda(GPU), (4, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFDataset(Dataset):\n",
    "    def __init__(self, root_path, limit=None):\n",
    "        print(root_path)\n",
    "        self.root_path = root_path\n",
    "        self.list_of_all_pickles = sorted(pathlib.Path(root_path).rglob('*/chopped-data-224-224/*.pickle'))\n",
    "        print('list of patches =', len(self.list_of_all_pickles))\n",
    "        if limit:\n",
    "            rng = np.random.default_rng(0)\n",
    "            self.list_of_all_pickles = rng.choice(self.list_of_all_pickles, size=limit, replace=False)\n",
    "        self.get_class = dict()\n",
    "        class_folders = list(pathlib.Path(root_path).glob('*/'))\n",
    "        for class_folder in class_folders:\n",
    "            class_index = -1\n",
    "            metadata_path = list(class_folder.rglob('*.sigmf-meta'))[0] #changed from [0]\n",
    "            with open(metadata_path) as fp:\n",
    "                metadata = json.load(fp)\n",
    "                class_index = int(metadata[\"global\"][\"core:class\"])\n",
    "            self.get_class[str(class_folder.stem)] = class_index\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_of_all_pickles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.list_of_all_pickles[idx]\n",
    "        with open(filepath, 'rb') as fp:\n",
    "            tensor = pickle.load(fp)['bounded']\n",
    "        foldername = filepath.parts[7] # changed from [7] relative to path depth\n",
    "        label = self.get_class[foldername]\n",
    "#         one_hot_label = np.zeros(12).astype(int) # creating one hot vector\n",
    "#         print('dataloader class number = ', label)\n",
    "        one_hot_label = np.zeros(12).astype(int) # creating one hot vector, needs to be float\n",
    "        one_hot_label[label] = 1\n",
    "#         print('dataloader One hot = ', one_hot_label)\n",
    "#         sys.exit('One hot vector testing')\n",
    "        #return (tensor, label) # this is a tuple\n",
    "        return {'data': tensor, 'label': one_hot_label, 'label_int': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFDataset2(Dataset):\n",
    "    def __init__(self, root_path, limit=None):\n",
    "        print(root_path)\n",
    "        self.root_path = root_path\n",
    "        self.list_of_all_pickles = sorted(pathlib.Path(root_path).rglob('*/chopped-data-224-224/*.pickle'))\n",
    "        print('list of patches =', len(self.list_of_all_pickles))\n",
    "        if limit:\n",
    "            rng = np.random.default_rng(0)\n",
    "            self.list_of_all_pickles = rng.choice(self.list_of_all_pickles, size=limit, replace=False)\n",
    "        self.get_class = dict()\n",
    "        class_folders = list(pathlib.Path(root_path).glob('*/'))\n",
    "        for class_folder in class_folders:\n",
    "            class_index = -1\n",
    "            metadata_path = list(class_folder.rglob('*.sigmf-meta'))[0] #changed from [0]\n",
    "            with open(metadata_path) as fp:\n",
    "                metadata = json.load(fp)\n",
    "                class_index = int(metadata[\"global\"][\"core:class\"])\n",
    "            self.get_class[str(class_folder.stem)] = class_index\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_of_all_pickles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.list_of_all_pickles[idx]\n",
    "        with open(filepath, 'rb') as fp:\n",
    "            tensor = pickle.load(fp)['bounded']\n",
    "        foldername = filepath.parts[7] # changed from [7] relative to path depth\n",
    "        label = self.get_class[foldername]\n",
    "#         one_hot_label = np.zeros(12).astype(int) # creating one hot vector\n",
    "#         print('dataloader class number = ', label)\n",
    "        one_hot_label = np.zeros(12).astype(int) # creating one hot vector, needs to be float\n",
    "        one_hot_label[label] = 1\n",
    "#         print('dataloader One hot = ', one_hot_label)\n",
    "#         sys.exit('One hot vector testing')\n",
    "        #return (tensor, label) # this is a tuple\n",
    "        return {'data': tensor, 'label': one_hot_label, 'label_int': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patch_limit = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patch_limit)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, val_data in enumerate(validation_data, 0):\n",
    "#     for i, rf_data in enumerate(val_data, 0): \n",
    "#         inputs = rf_data['data']\n",
    "#         labels = rf_data['label']\n",
    "#         print('label shape', labels.shape)\n",
    "#         print('inputs shape = ', inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(inputs, labels):\n",
    "    if (classes == 2):\n",
    "#         print('Classes = ', classes)\n",
    "#         print('pre combine shape  = ', inputs.shape)\n",
    "        inputs_lower = inputs[:batches//2,:,:,:]\n",
    "#         print('inputs lower shape = ', inputs_lower.shape) # **** new print\n",
    "        inputs_upper = inputs[batches//2:,:,:,:]\n",
    "#         print('inputs upper shape = ', inputs_upper.shape) # **** new print\n",
    "        inputs = inputs_lower + inputs_upper # combine two classes\n",
    "#         print('inputs final shape = ', inputs.shape) # **** new print       \n",
    "        label_lower = labels[:batches//2,:]\n",
    "#         print('label lower = ', label_lower)\n",
    "        label_upper = labels[batches//2:,:]\n",
    "#         print('label upper = ', label_upper)\n",
    "        labels = torch.bitwise_or(label_lower,label_upper)\n",
    "#         print('labels combined = ', labels)\n",
    "    elif (classes == 3):\n",
    "#         print('Classes = ', classes)\n",
    "#         print('pre combine shape  = ', inputs.shape)\n",
    "        inputs_lower = inputs[:batches//3,:,:,:]\n",
    "#         print('inputs lower shape = ', inputs_lower.shape) # **** new print\n",
    "        inputs_mid = inputs[batches//3:128,:,:,:]\n",
    "#         print('inputs mid shape = ', inputs_mid.shape) # **** new print        \n",
    "        inputs_upper = inputs[128:,:,:,:]\n",
    "#         print('inputs upper shape = ', inputs_upper.shape) # **** new print\n",
    "        inputs = inputs_lower + inputs_mid + inputs_upper # combine three classes\n",
    "#         print('inputs final shape = ', inputs.shape) # **** new print\n",
    "        label_lower = labels[:batches//3,:]\n",
    "#         print('label lower = ', label_lower)\n",
    "        label_mid = labels[batches//3:128,:]\n",
    "#         print('label mid = ', label_mid)        \n",
    "        label_upper = labels[128:,:]\n",
    "#         print('label upper = ', label_upper)\n",
    "        labels1 = torch.bitwise_or(label_lower,label_mid)\n",
    "        labels = torch.bitwise_or(labels1,label_upper)\n",
    "#         print('labels combined = ', labels)\n",
    "#     sys.exit('multiclass testing') # exit program for testing\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(total): # Multiclass - Mixed patches\n",
    "#     batches = 64\n",
    "#     batches = batches*2# double net required actual batches for combining purpose math\n",
    "    print('batches = ', batches)\n",
    "    if (classes == 1):\n",
    "        test_patch_total = 88000 \n",
    "    if (classes == 2):    \n",
    "        test_patch_total = 87936//2 + 64 # accounting for 128 batches and remainder the original test total\n",
    "    if (classes == 3):    \n",
    "        test_patch_total = 87936//3 + 64 # accounting for 192 batches and remainder the original test total\n",
    "    print('total patch count = ', test_patch_total)\n",
    "    compare = .7\n",
    "    loss_plot = np.zeros(total)\n",
    "    total_plot = np.zeros(total//5+1)\n",
    "    print('training data length = ', len(training_data25))\n",
    "    batch_plot = np.zeros(len(training_data25)*total) # temporarily remove //100\n",
    "#     print('batch plot shape = ', batch_plot.shape)\n",
    "    batch_indexer = 0\n",
    "    for epoch in tqdm(range(total), desc=\"Epoch\"): \n",
    "        model.train()\n",
    "        start = timer()\n",
    "#         for i, rf_data in enumerate(training_data, 0):\n",
    "        for i in range(len(training_data25)//classes): # divide to temp reduce training loop  \n",
    "            # 1msps patchs ######################################################################\n",
    "            rf_data1 = next(iter(training_data1))\n",
    "            inputs = rf_data1['data']\n",
    "            inputs = torch.squeeze(inputs, dim=1)\n",
    "            inputs = inputs.permute(0,3,1,2).contiguous()\n",
    "            current_batches, b, c, d = inputs.shape\n",
    "#             print('iteration = ', i, 'current batches = ', current_batches)\n",
    "            labels = rf_data1['label'] \n",
    "            if ((current_batches == batches) and (classes != 1)):\n",
    "                inputs, labels = multiclass(inputs, labels)\n",
    "#                 print('class = ', classes)\n",
    "#             print('labels shape = ', labels.shape)\n",
    "#             print('inputs shape = ', inputs.shape)\n",
    "            if (current_batches != batches):\n",
    "                print('left over patches = ',current_batches)\n",
    "            batch_dim, b, c, d = inputs.shape #using NEW inputs shape\n",
    "            labels = labels.to(torch.float)\n",
    "#             print('label example =', labels[0,:]) # **** new print\n",
    "#             print('label vector shape', labels.shape) # **** new print\n",
    "#             print('label vector type', type(labels)) # **** new print\n",
    "            # *********************** Print out a patch to verify process **************************\n",
    "#             stft_plot1 =  10*np.log10(np.abs(inputs[0, 0, :, :]+eps))\n",
    "#             stft_plot1 = np.squeeze(stft_plot1, axis=0)\n",
    "#             plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#             plt.show()          \n",
    "            # **************************************************************************************\n",
    "#             sys.exit('shape testing') # exit program for testing\n",
    "            # add som noise\n",
    "#             c2 = torch.FloatTensor(a).uniform_(r1_c2, r2_c2)\n",
    "            c2 = 1 # lock down noise to nominal\n",
    "            for batch_num in range(batch_dim):\n",
    "                inputs[batch_num,:,:,:] = inputs[batch_num,:,:,:] + (((var_noise*c2)**0.5)*torch.randn(1, 4, 224, 224))   \n",
    "            inputs = Variable(inputs.cuda(GPU))\n",
    "#             labels = rf_data['label'] # moved it up\n",
    "            labels = labels.cuda(GPU)\n",
    "            outputs_logits, outputs_sig = model(inputs)\n",
    "            loss = criterion(outputs_logits, labels) # used with nn.BCEWithLogitsLoss()\n",
    "#                 loss = criterion(outputs_sig, labels) # used with nn.BCEloss\n",
    "#                 print('loss = ', loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 25msps patchs ######################################################################\n",
    "            rf_data25 = next(iter(training_data25))\n",
    "            inputs = rf_data25['data']\n",
    "            inputs = torch.squeeze(inputs, dim=1)\n",
    "            inputs = inputs.permute(0,3,1,2).contiguous()\n",
    "            current_batches, b, c, d = inputs.shape\n",
    "#             print('iteration = ', i, 'current batches = ', current_batches)\n",
    "            labels = rf_data25['label'] \n",
    "            if ((current_batches == batches) and (classes != 1)):\n",
    "                inputs, labels = multiclass(inputs, labels)\n",
    "#                 print('class = ', classes)\n",
    "#             print('labels shape = ', labels.shape)\n",
    "#             print('inputs shape = ', inputs.shape)\n",
    "            if (current_batches != batches):\n",
    "                print('left over patches = ',current_batches)\n",
    "            batch_dim, b, c, d = inputs.shape #using NEW inputs shape\n",
    "            labels = labels.to(torch.float)\n",
    "#             print('label example =', labels[0,:]) # **** new print\n",
    "#             print('label vector shape', labels.shape) # **** new print\n",
    "#             print('label vector type', type(labels)) # **** new print\n",
    "            # *********************** Print out a patch to verify process **************************\n",
    "#             stft_plot1 =  10*np.log10(np.abs(inputs[0, 0, :, :]+eps))\n",
    "#             stft_plot1 = np.squeeze(stft_plot1, axis=0)\n",
    "#             plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#             plt.show()          \n",
    "            # **************************************************************************************\n",
    "#             sys.exit('shape testing') # exit program for testing\n",
    "            # add som noise\n",
    "#             c2 = torch.FloatTensor(a).uniform_(r1_c2, r2_c2)\n",
    "            c2 = 1 # lock down noise to nominal\n",
    "            for batch_num in range(batch_dim):\n",
    "                inputs[batch_num,:,:,:] = inputs[batch_num,:,:,:] + (((var_noise*c2)**0.5)*torch.randn(1, 4, 224, 224))   \n",
    "            inputs = Variable(inputs.cuda(GPU))\n",
    "#             labels = rf_data['label'] # moved it up\n",
    "            labels = labels.cuda(GPU)\n",
    "            outputs_logits, outputs_sig = model(inputs)\n",
    "            loss = criterion(outputs_logits, labels) # used with nn.BCEWithLogitsLoss()\n",
    "#                 loss = criterion(outputs_sig, labels) # used with nn.BCEloss\n",
    "#                 print('loss = ', loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#                 print('loss = ', loss)\n",
    "#         print('ResNet ouput = ', outputs)\n",
    "        end = timer()\n",
    "        batch_time = end - start\n",
    "#         print('train total batches =', batch_sum)\n",
    "        #***************************************************************************************\n",
    "        print('batch time = ', batch_time)\n",
    "        print('************************* start *************************')\n",
    "#         sys.exit('resnet testing') # exit program for testing\n",
    "        total_correct_patches = grand_total = 0\n",
    "        start_test = timer()\n",
    "        model.eval()\n",
    "        for testing in validation_data1:\n",
    "            t = train_val(testing)\n",
    "            print('Total 1msps correct = {:.2f}%'.format(t/(24000/classes)*100))\n",
    "            total_correct_patches = total_correct_patches + t\n",
    "        for testing in validation_data5:\n",
    "            t = train_val(testing)\n",
    "            print('Total 5msps correct = {:.2f}%'.format(t/(20004/classes)*100))\n",
    "            total_correct_patches = total_correct_patches + t          \n",
    "        for testing in validation_data10:\n",
    "            t = train_val(testing)\n",
    "            print('Total 10msps correct = {:.2f}%'.format(t/(20004/classes)*100))\n",
    "            total_correct_patches = total_correct_patches + t            \n",
    "        for testing in validation_data25:\n",
    "            t = train_val(testing)\n",
    "            print('Total 25msps correct = {:.2f}%'.format(t/(24000/classes)*100))\n",
    "            total_correct_patches = total_correct_patches + t            \n",
    "           \n",
    "        grand_total = total_correct_patches/test_patch_total\n",
    "#         sys.exit('resnet testing') # exit program for testing\n",
    "#         print('batch indexer = ', batch_indexer)\n",
    "        batch_plot[batch_indexer] = grand_total*100\n",
    "        batch_indexer = batch_indexer + 1\n",
    "    #     print('Batch number = ', i, 'of', len(training_data))\n",
    "        print('Total % correct = {:.2f}%'.format(grand_total*100))         \n",
    "        model.train \n",
    "        end_test = timer()\n",
    "        test_time = end_test - start_test\n",
    "        print('test time = ', test_time)\n",
    "        print('*************************** end ***************************')\n",
    "        #****************************************************************************************         \n",
    "        save_model(epoch,loss)\n",
    "        tqdm.write('___________________________________________')\n",
    "        tqdm.write(\"Epoch {} Loss {:.10f} \".format(epoch+1, loss.data*1)) \n",
    "        tqdm.write('___________________________________________') \n",
    "        if (grand_total >= .97):\n",
    "            break\n",
    "    return loss_plot, batch_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "88008/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_combined_data(total): # Multiclass - Mixed patches\n",
    "#     batches = 64\n",
    "#     batches = batches*2# double net required actual batches for combining purpose math\n",
    "    i_batch = 100\n",
    "    i_main = 0\n",
    "    print('batches = ', batches)\n",
    "    if (classes == 1):\n",
    "        test_patch_total = 88008\n",
    "    if (classes == 2):    \n",
    "        test_patch_total = 88008//2 # (88008//2)%128=100 128 batches and remainder the original test total\n",
    "    if (classes == 3):    \n",
    "        test_patch_total = 88008//3 # (88008//3)%192=152 192 batches and remainder the original test total\n",
    "    print('total patch count = ', test_patch_total)\n",
    "    compare = .7\n",
    "    loss_plot = np.zeros(len(training_data)*total)\n",
    "    total_plot = np.zeros(len(training_data)*total)\n",
    "    print('training data length = ', len(training_data))\n",
    "    # Based on combined training data **************************************************\n",
    "    batch_plot = np.zeros(len(training_data)*total) # temporarily remove //100\n",
    "    plot_1msps = np.zeros(len(training_data)*total)\n",
    "    plot_5msps = np.zeros(len(training_data)*total)\n",
    "    plot_10msps = np.zeros(len(training_data)*total)\n",
    "    plot_25msps = np.zeros(len(training_data)*total)\n",
    "    #************************************************************************************\n",
    "#     print('batch plot shape = ', batch_plot.shape)\n",
    "    batch_indexer = 0\n",
    "#     loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer = load_plot_data(loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(total), desc=\"Epoch\"): \n",
    "#         start = timer()\n",
    "        for i, rf_data in enumerate(training_data, 0): \n",
    "            start = timer()\n",
    "            inputs = rf_data['data']\n",
    "            inputs = torch.squeeze(inputs, dim=1)\n",
    "            inputs = inputs.permute(0,3,1,2).contiguous()\n",
    "            current_batches, b, c, d = inputs.shape\n",
    "#             print('iteration = ', i, 'current batches = ', current_batches)\n",
    "            labels = rf_data['label'] \n",
    "            if ((current_batches == batches) and (classes != 1)):\n",
    "                inputs, labels = multiclass(inputs, labels)\n",
    "#                 print('class = ', classes)\n",
    "#             print('labels shape = ', labels.shape)\n",
    "#             print('inputs shape = ', inputs.shape)\n",
    "            if (current_batches != batches):\n",
    "                print('left over patches = ',current_batches)\n",
    "#             sys.exit('resnet testing') # exit program for testing\n",
    "            batch_dim, b, c, d = inputs.shape #using NEW inputs shape\n",
    "            labels = labels.to(torch.float)\n",
    "#             print('label example =', labels[0,:]) # **** new print\n",
    "#             print('label vector shape', labels.shape) # **** new print\n",
    "#             print('label vector type', type(labels)) # **** new print\n",
    "            # *********************** Print out a patch to verify process **************************\n",
    "#             stft_plot1 =  10*np.log10(np.abs(inputs[0, 0, :, :]+eps))\n",
    "#             stft_plot1 = np.squeeze(stft_plot1, axis=0)\n",
    "#             plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#             plt.show()          \n",
    "            # **************************************************************************************\n",
    "#             sys.exit('shape testing') # exit program for testing\n",
    "            # add som noise\n",
    "#             c2 = torch.FloatTensor(a).uniform_(r1_c2, r2_c2)\n",
    "            c2 = 1 # lock down noise to nominal\n",
    "            for batch_num in range(batch_dim):\n",
    "                inputs[batch_num,:,:,:] = inputs[batch_num,:,:,:] + (((var_noise*c2)**0.5)*torch.randn(1, 4, 224, 224))   \n",
    "            inputs = Variable(inputs.cuda(GPU))\n",
    "#             labels = rf_data['label'] # moved it up\n",
    "            labels = labels.cuda(GPU)\n",
    "            outputs_logits, outputs_sig = model(inputs)\n",
    "            loss = criterion(outputs_logits, labels) # used with nn.BCEWithLogitsLoss()\n",
    "#                 loss = criterion(outputs_sig, labels) # used with nn.BCEloss\n",
    "#                 print('loss = ', loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if 1500<=i_main<=100000:\n",
    "                i_batch = 1000\n",
    "            if (i_main % i_batch == 0) and i>0:\n",
    "                print('iter epoch = ', i)\n",
    "                print('iter batch = ', i_batch)\n",
    "                print('i_main = ', i_main)\n",
    "                save_model(epoch,loss,i_main)\n",
    "                loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps = \\\n",
    "                validation_check(loss,epoch,start, test_patch_total,classes,loss_plot, \\\n",
    "                batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer)\n",
    "                batch_indexer = batch_indexer + 1\n",
    "            i_main = i_main +1\n",
    "    return loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_check(loss,epoch,start,test_patch_total,classes,loss_plot, batch_plot, plot_1msps, \n",
    "                     plot_5msps, plot_10msps, plot_25msps, batch_indexer):       \n",
    "    end = timer()\n",
    "    batch_time = end - start\n",
    "    print('batch time = ', batch_time)\n",
    "    print('************************* start *************************')    \n",
    "    total_correct_patches = grand_total = 0\n",
    "    start_test = timer()\n",
    "    model.eval()\n",
    "    for testing in validation_data1:\n",
    "        t = train_val(testing)\n",
    "        print('Total 1msps correct = {:.2f}%'.format(t/(24000/classes)*100))\n",
    "        total_correct_patches = total_correct_patches + t\n",
    "#         plot_1msps[batch_indexer] = t/(test_patch_total/4)\n",
    "        plot_1msps[batch_indexer] = t/(24000/classes)\n",
    "    for testing in validation_data5:\n",
    "        t = train_val(testing)\n",
    "        print('Total 5msps correct = {:.2f}%'.format(t/(20004/classes)*100))\n",
    "        total_correct_patches = total_correct_patches + t   \n",
    "#         plot_5msps[batch_indexer] = t/(test_patch_total/4)\n",
    "        plot_5msps[batch_indexer] = t/(20004/classes)\n",
    "    for testing in validation_data10:\n",
    "        t = train_val(testing)\n",
    "        print('Total 10msps correct = {:.2f}%'.format(t/(20004/classes)*100))\n",
    "        total_correct_patches = total_correct_patches + t  \n",
    "#         plot_10msps[batch_indexer] = t/(test_patch_total/4)\n",
    "        plot_10msps[batch_indexer] = t/(20004/classes)\n",
    "    for testing in validation_data25:\n",
    "        t = train_val(testing)\n",
    "        print('Total 25msps correct = {:.2f}%'.format(t/(24000/classes)*100))\n",
    "        total_correct_patches = total_correct_patches + t  \n",
    "#         plot_25msps[batch_indexer] = t/(test_patch_total/4)\n",
    "        plot_25msps[batch_indexer] = t/(24000/classes)\n",
    "    grand_total = total_correct_patches/(test_patch_total)\n",
    "    #         sys.exit('resnet testing') # exit program for testing\n",
    "    #         print('batch indexer = ', batch_indexer)\n",
    "    batch_plot[batch_indexer] = grand_total\n",
    "#     batch_indexer = batch_indexer + 1\n",
    "    #     print('Batch number = ', i, 'of', len(training_data))\n",
    "    print('Total % correct {:.2f}%'.format(grand_total*100))         \n",
    "    model.train \n",
    "    end_test = timer()\n",
    "    test_time = end_test - start_test\n",
    "    #***********************************************************\n",
    "    #                       Save plotting data\n",
    "    #***********************************************************\n",
    "    save_plot_data(loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer)\n",
    "    #***********************************************************\n",
    "    print('test time = ', test_time)\n",
    "    print('*************************** end ***************************')\n",
    "    #****************************************************************************************         \n",
    "#     save_model(epoch,loss)\n",
    "    tqdm.write('___________________________________________')\n",
    "    tqdm.write(\"Epoch {} Loss {:.10f} \".format(epoch+1, loss.data*1)) \n",
    "    tqdm.write('___________________________________________') \n",
    "    return loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_data(loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer):\n",
    "    # path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "    # os.chdir(path_plot_fig)\n",
    "    np.save('resnet50_4ch_loss_plot3_20211213', np.asarray(loss_plot))\n",
    "    np.save('resnet50_4ch_batch_plot3_20211213', np.asarray(batch_plot))\n",
    "    np.save('resnet50_4ch_plot_1msps3_20211213', np.asarray(plot_1msps))\n",
    "    np.save('resnet50_4ch_plot_5msps3_20211213', np.asarray(plot_5msps))\n",
    "    np.save('resnet50_4ch_plot_10msps3_20211213', np.asarray(plot_10msps))\n",
    "    np.save('resnet50_4ch_plot_25msps3_20211213', np.asarray(plot_25msps))\n",
    "    np.save('resnet50_4ch_batch_indexer3_20211213', np.asarray(batch_indexer))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_plot_data(loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer):\n",
    "    # path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "    # os.chdir(path_plot_fig)\n",
    "    loss_plot = np.load('resnet50_4ch_loss_plot3_20211213.npy')\n",
    "    batch_plot = np.load('resnet50_4ch_batch_plot3_20211213.npy')\n",
    "    plot_1msps = np.load('resnet50_4ch_plot_1msps3_20211213.npy')\n",
    "    plot_5msps = np.load('resnet50_4ch_plot_5msps3_20211213.npy')\n",
    "    plot_10msps = np.load('resnet50_4ch_plot_10msps3_20211213.npy')\n",
    "    plot_25msps = np.load('resnet50_4ch_plot_25msps3_20211213.npy')\n",
    "    batch_indexer = np.load('resnet50_4ch_batch_indexer3_20211213.npy')\n",
    "    return loss_plot, batch_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps, batch_indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(val_data): # used for MULTI class validation\n",
    "    noise_label = np.zeros(12) # used for validation with noise\n",
    "    noise_label[8] = 1\n",
    "    noise_label = torch.tensor(noise_label)\n",
    "    with torch.no_grad():\n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = 0\n",
    "        for i, rf_data in enumerate(val_data, 0): \n",
    "            inputs = rf_data['data']\n",
    "            inputs = torch.squeeze(inputs, dim=1)\n",
    "            inputs = inputs.permute(0,3,1,2).contiguous() \n",
    "            current_batches, b, c, d = inputs.shape\n",
    "#             print('iteration = ', i, 'current batches = ', current_batches)\n",
    "            labels = rf_data['label'] \n",
    "            if ((current_batches == batches) and (classes != 1)):\n",
    "                inputs, labels = multiclass(inputs, labels)\n",
    "                # *********************** Print out a patch to verify process **************************\n",
    "    #             stft_plot1 =  10*np.log10(np.abs(inputs[0, 0, :, :]+eps))\n",
    "    #             stft_plot1 = np.squeeze(stft_plot1, axis=0)\n",
    "    #             plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "    #             plt.show()          \n",
    "                # **************************************************************************************\n",
    "    #             sys.exit('shape testing') # exit program for testing\n",
    "                # add som noise\n",
    "    #             c2 = torch.FloatTensor(a).uniform_(r1_c2, r2_c2)\n",
    "            batch_dim, b, c, d = inputs.shape #using NEW inputs shape\n",
    "            labels = labels.to(torch.float)        \n",
    "            c2 = 1 # lock down noise to nominal\n",
    "            for batch_num in range(batch_dim):\n",
    "                inputs[batch_num,:,:,:] = inputs[batch_num,:,:,:] + (((var_noise*c2)**0.5)*torch.randn(1, 4, 224, 224)) \n",
    "            inputs = Variable(inputs.cuda(GPU))\n",
    "            labels_int = rf_data['label_int']\n",
    "            labels = labels.cuda(GPU)\n",
    "            optimizer.zero_grad() \n",
    "            outputs_logits, outputs_sig = model(inputs)\n",
    "            if (classes ==1):\n",
    "                predicted = outputs_logits.data # using logits output for single patch class validation \n",
    "#                 print('logits out = ', predicted)\n",
    "                _, predicted = torch.max(outputs_logits.data, 1)\n",
    "#                 print('predicted max = ', predicted)\n",
    "#                 predicted = torch.zeros(predicted.shape)\n",
    "#                 predicted[(torch.arange(len(predicted)).unsqueeze(1), torch.topk(predicted,2).indices)] = 1                \n",
    "            else:\n",
    "                predicted = torch.round(outputs_sig.data) # using sigmoid output for multiclass patch validation \n",
    "#                 print('predicted rounded =', predicted)\n",
    "#                 one_hot_label = np.zeros(12).astype(int) # creating one hot vector\n",
    "#                 one_hot_label[label_int] = 1\n",
    "            for b in range(len(predicted)):\n",
    "                if (classes == 1):\n",
    "                    label_integer = labels_int[b].detach().cpu().numpy()\n",
    "                    pred = predicted[b].detach().cpu().numpy()\n",
    "                    if (label_integer == pred): # using integer values\n",
    "                        accumulated_corrects = accumulated_corrects+1                    \n",
    "                else:\n",
    "                    if torch.equal(predicted[b], labels[b]):\n",
    "                        accumulated_corrects = accumulated_corrects+1\n",
    "                    elif torch.equal(predicted[b].detach().cpu().to(torch.int), torch.bitwise_or(labels[b].detach().cpu().to(torch.int),noise_label.to(torch.int))):\n",
    "                        accumulated_corrects = accumulated_corrects+1 # for noise predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    return accumulated_corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START one validation test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batches = 64\n",
    "# classes = 3\n",
    "# batches = batches*classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patch_limit = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patch_limit)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('batches = ', batches)\n",
    "# if (classes == 1):\n",
    "#     test_patch_total = 88000 \n",
    "# if (classes == 2):    \n",
    "#     test_patch_total = 87936//2 + 64 # accounting for 128 batches and remainder the original test total\n",
    "# if (classes == 3):    \n",
    "#     test_patch_total = 87936//3 + 64 # accounting for 192 batches and remainder the original test total\n",
    "# print('total patch count = ', test_patch_total)\n",
    "# total_correct_patches = grand_total = 0\n",
    "# start_test = timer()\n",
    "# model.eval()\n",
    "# for testing in validation_data:\n",
    "#     t = train_val(testing)\n",
    "#     total_correct_patches = total_correct_patches + t           \n",
    "# grand_total = total_correct_patches/test_patch_total\n",
    "# print('Total % correct {:.2f}%'.format(grand_total*100))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END validation test run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Segmented Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Dataloader with labels\n",
    "class inference_dataloader_segmented_live(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataPath = path\n",
    "        self.num_classes = 12\n",
    "        self.num_examples = 1 # use only 1 for semi-live inferencing\n",
    "    def __getitem__(self, index):\n",
    "        sigmf_data = np.array(data_IQ_list_val[index]) \n",
    "        print('sigmf_data = ', sigmf_data.shape)\n",
    "        frequency, time, dims1 = sigmf_data.shape\n",
    "        print('frequency = ', frequency, '  time = ', time)\n",
    "        data_IQ = []\n",
    "        data_IQ_temp2 = []\n",
    "        seg_t = 224  \n",
    "        seg_f = 224 \n",
    "        seg_time = time//seg_t\n",
    "        seg_freq = frequency//seg_f\n",
    "        print('seg_time = ', seg_time, 'seg_freq = ', seg_freq)\n",
    "        # Segment the time axis\n",
    "        for j in range(seg_time): \n",
    "                # Segment the frequency axis\n",
    "                for k in range(seg_freq): \n",
    "                    IQ = sigmf_data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                    data_IQ_temp2.append(IQ)            \n",
    "        data_IQ = np.array(data_IQ_temp2)\n",
    "        print('data_IQ shape = ', data_IQ.shape)\n",
    "        loop_counter, dim1, dim2, dim3 = data_IQ.shape\n",
    "        TRUTH =  meta_encoder(meta_list_val, self.num_classes)\n",
    "        TRUTH = TRUTH.astype(np.float32)\n",
    "        return torch.from_numpy(data_IQ),torch.from_numpy(TRUTH), loop_counter, seg_freq\n",
    "    def __len__(self):\n",
    "        return self.num_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Dataloader with labels\n",
    "class inference_dataloader_segmented(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataPath = path\n",
    "        self.num_classes = 12\n",
    "        self.num_examples = 1 # uses a LOT of memory for more than 1 25MSPS STFT\n",
    "    def __getitem__(self, index):\n",
    "        sigmf_data = np.array(data_IQ_list_val[index]) \n",
    "        print('sigmf_data = ', sigmf_data.shape)\n",
    "        frequency, time, dims1 = sigmf_data.shape\n",
    "        print('frequency = ', frequency, '  time = ', time)\n",
    "        data_IQ = []\n",
    "        data_IQ_temp2 = []\n",
    "        seg_t = 224  \n",
    "        seg_f = 224 \n",
    "        seg_time = time//seg_t\n",
    "        seg_freq = frequency//seg_f\n",
    "        print('seg_time = ', seg_time, 'seg_freq = ', seg_freq)\n",
    "        # Segment the time axis\n",
    "        for j in range(seg_time): \n",
    "                # Segment the frequency axis\n",
    "                for k in range(seg_freq): \n",
    "                    IQ = sigmf_data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                    data_IQ_temp2.append(IQ)            \n",
    "        data_IQ = np.array(data_IQ_temp2)\n",
    "        print('data_IQ shape = ', data_IQ.shape)\n",
    "        loop_counter, dim1, dim2, dim3 = data_IQ.shape\n",
    "        TRUTH =  meta_encoder(meta_list_val, self.num_classes)\n",
    "        TRUTH = TRUTH.astype(np.float32)\n",
    "        return torch.from_numpy(data_IQ),torch.from_numpy(TRUTH), loop_counter, seg_freq\n",
    "    def __len__(self):\n",
    "        return self.num_examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_read():    \n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path_val)\n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"validation file name = \", meta)\n",
    "    # Load validation sigmf-data files\n",
    "    meta_list_val = read_meta(meta_files_validation)\n",
    "    data_IQ_list_val = iq_read(data_files_validation)\n",
    "    return data_IQ_list_val, meta_list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_read():\n",
    "    print('testing_read function')\n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path_val)\n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"testing file name = \", meta)\n",
    "    meta_list_val = read_meta(meta_files_validation)\n",
    "    data_IQ_list_val = iq_read_test_file(data_files_validation)\n",
    "    return data_IQ_list_val, meta_list_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changed to get test data from different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_read_old(msps):    \n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path_ram) \n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"inference file name = \", meta)\n",
    "    # Load validation sigmf-data files\n",
    "    meta_list_val = read_meta(meta_files_validation)\n",
    "    data_IQ_list_val = iq_read_test_live_old(data_files_validation,msps)\n",
    "    return data_IQ_list_val, meta_list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated 20210609 to save memory\n",
    "def inference_read(msps):    \n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path_ram)\n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"inference file name = \", meta)\n",
    "    return data_files_validation, meta_files_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated 2021025 to save memory\n",
    "def inference_read_file(msps,path):    \n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path)\n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"inference file name = \", meta)\n",
    "    return data_files_validation, meta_files_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_read_file_old(msps,path):    \n",
    "    # Inference DATA READING ************************************************\n",
    "    # read in validation IQ and meta data\n",
    "    os.chdir(path)\n",
    "    data_files_validation = sorted(glob.glob('*.sigmf-data'))\n",
    "    meta_files_validation = sorted(glob.glob('*.sigmf-meta'))\n",
    "    for meta in meta_files_validation:\n",
    "        all_meta_data = json.load(open(meta))\n",
    "        print(\"inference file name = \", meta)\n",
    "    # Load validation sigmf-data files\n",
    "    meta_list_val = read_meta(meta_files_validation)\n",
    "    data_IQ_list_val = iq_read_test_file(data_files_validation,msps)\n",
    "    return data_IQ_list_val, meta_list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_IQ_data_one_file_at_a_time_original(center_freq_file, list_of_IQ_data, list_of_labels):    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        start_frequency = (center_freq_file)\n",
    "        print('start_frequency = ', start_frequency/1000000)\n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        histogram_global = {}\n",
    "        for data in list_of_IQ_data:\n",
    "            # shape of \"data\" should be (513, 1900000000) \n",
    "            freq_offset = 0\n",
    "            match_freq = start_frequency\n",
    "            histogram = np.zeros(12)\n",
    "\n",
    "            # chop \"data\" into the required squares\n",
    "            frequency, time, dims1 = data.shape\n",
    "            list_of_patches = []\n",
    "            seg_t = 224  \n",
    "            seg_f = 224 \n",
    "            seg_time = time//seg_t\n",
    "            seg_freq = frequency//seg_f\n",
    "            # Segment the time axis\n",
    "            for j in range(seg_time): \n",
    "                    # Segment the frequency axis\n",
    "                    for k in range(seg_freq): \n",
    "                        IQ = data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                        list_of_patches.append(IQ)            \n",
    "            # loop through each square  in list_of_squares and score each\n",
    "            freq_increment = (Fs*msps/2)/seg_freq\n",
    "            histogram_frequency = np.zeros(len(list_of_patches))\n",
    "            denom = len(list_of_patches)\n",
    "            count_noise = 0\n",
    "            count_center = 0\n",
    "            for (j, patch) in enumerate(list_of_patches):\n",
    "                num_correct, accuracy = 0, 0\n",
    "                patch = torch.Tensor(patch) # convert path to tensor\n",
    "                patch = patch.unsqueeze(0) # give the patch a fake batch axis\n",
    "                patch = patch.permute(0,3,1,2) # move the channel axis to the front\n",
    "                patch = patch.contiguous().cuda(GPU) # move the tensor to GPU\n",
    "                predicted_class = int(torch.argmax(model(patch))) # gets the index of the largest probability\n",
    "                histogram[predicted_class] += 1\n",
    "                histogram_global[predicted_class] = histogram_global.get(predicted_class, 0) + 1\n",
    "                if predicted_class == 8:\n",
    "                    count_noise += 1\n",
    "                if predicted_class == 9:\n",
    "                    count_center += 1\n",
    "                match_freq = match_freq + freq_offset*freq_increment\n",
    "                histogram_frequency[j] = match_freq/1000000\n",
    "            # print statistics\n",
    "            histo_stats_freq_file(histogram_frequency, msps)\n",
    "            print('************************* Probabilities ********************************')\n",
    "            print('----------------------------WAVEFORMS-----------------------------------')\n",
    "            if (denom == 0):\n",
    "                print('Nothing but noise')\n",
    "            else:\n",
    "                print('LoRa 125 = {:.2f}%'.format(histogram[0]/denom*100))\n",
    "                print('GD55 DMR = {:.2f}%'.format(histogram[1]/denom*100))\n",
    "                print('NFM = {:.2f}%'.format(histogram[2]/denom*100))\n",
    "                print('TYT = {:.2f}'.format(histogram[3]/denom*100))\n",
    "                print('Vodeson Doorbell = {:.2f}%'.format(histogram[4]/denom*100))\n",
    "                print('clickndig = {:.2f}%'.format(histogram[5]/denom*100))\n",
    "                print('Sado doorbell = {:.2f}%'.format(histogram[6]/denom*100))\n",
    "                print('LoRa 250 = {:.2f}%'.format(histogram[7]/denom*100))\n",
    "                print('light switch = {:.2f}%'.format(histogram[10]/denom*100))\n",
    "                print('YSF = {:.2f}%'.format(histogram[11]/denom*100))\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print('***************************** noise and fft ****************************')\n",
    "            print('noise matches = ', count_noise)\n",
    "            print('center fft matches = ', count_center)\n",
    "            print('TOTAL patch count = ', len(list_of_patches))\n",
    "            print('***************************** Finished *********************************')\n",
    "    return histogram_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # inference ************************************************************\n",
    "def testing_file(msps):    \n",
    "        large_width = 400\n",
    "        np.set_printoptions(precision=2,floatmode='fixed', linewidth=large_width)\n",
    "        model.eval()\n",
    "        V = data.DataLoader(inference_dataloader_segmented(), batch_size=1)\n",
    "        start_frequency = (center_freq_file)\n",
    "        match_freq = start_frequency\n",
    "        print('start_frequency = ', start_frequency/1000000)\n",
    "        freq_offset = 0       \n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = 0      \n",
    "        with torch.no_grad():\n",
    "            for i, rf_data in enumerate(V, 0):   \n",
    "                accumulated_corrects = 0\n",
    "                percent_correct = 0\n",
    "                target_to_int = 0\n",
    "                inputs, target, counter, seg_freq = rf_data \n",
    "                print('testing counter = ', counter, 'seg_freq =', seg_freq)\n",
    "#                 print('seg_freq = ', seg_freq)\n",
    "#**************************** Print segmented pics ***********************************\n",
    "#                 stft_plot = np.squeeze(inputs, axis=0)\n",
    "#                 fig=plt.figure(figsize=(8,8))\n",
    "#                 ncols = 5\n",
    "#                 nrows = 5\n",
    "#                 range_plot = 1\n",
    "#                 for x in range(1,22): # need to figure out how to not hard code this ********************* <-----\n",
    "#                     stft_mean, stft_std = histo_stats(stft_plot[x,:,:,:])\n",
    "#                     if (x>=range_plot and x<(range_plot+25)):\n",
    "#                         stft_plot1 =  10*np.log10(np.abs(stft_plot[x, :, :, 0]+eps))\n",
    "#                         stft_plot1 = np.squeeze(stft_plot1, axis=0)\n",
    "#                         fig.add_subplot(nrows, ncols, x-range_plot+1)\n",
    "#                         plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#                 plt.show()\n",
    "#*************************************************************************************\n",
    "                freq_increment = (Fs*msps/2)/seg_freq.detach().cpu().numpy().item()\n",
    "                print('freq_increment = ', freq_increment)\n",
    "                print('TESTING inputs SHAPE = ', inputs.shape)\n",
    "                target = Variable(target.cuda(GPU)) \n",
    "#                 print('input in   = ', inputs.shape)\n",
    "                inputs = torch.squeeze(inputs, dim=0)\n",
    "#                 print('input out  = ', inputs.shape)\n",
    "                inputs = inputs.permute(0,3,1,2).contiguous()\n",
    "#                 print('counter convert stuff = ', counter, type(counter.numpy()))\n",
    "                inputs = Variable(inputs.cuda(GPU))\n",
    "#                 print('permuted shape = ', inputs.shape)\n",
    "                freq_count = 0 # keep track of array position\n",
    "                freq_histo = np.zeros(counter.numpy())\n",
    "                for j in range(counter):\n",
    "                    inputs2 = inputs[j,:,:,:]\n",
    "                    inputs2 = torch.unsqueeze(inputs2,0)\n",
    "                    outputs = model(inputs2)\n",
    "                    _, predicted = torch.max(outputs.data, 1) \n",
    "#******************************* Print prediction range to match pics above ***********        \n",
    "#                     if (j>=range_plot and j<(range_plot+25)):                    \n",
    "#                         print(\"j= \",j,' ',outputs.data.detach().cpu().numpy())\n",
    "#                         print('prediction = ', predicted.detach().cpu().numpy())\n",
    "#*************************************************************************************               \n",
    "                    total = total +1  # Increment the total count\n",
    "                    match_freq = match_freq + freq_offset*freq_increment\n",
    "                    if (predicted.detach().cpu().numpy() == 0):\n",
    "                        c0 = c0 + 1  \n",
    "                        freq_histo[j] = match_freq/1000000\n",
    "                    if (predicted.detach().cpu().numpy() == 1):\n",
    "                        c1 = c1 + 1\n",
    "                        freq_histo[j] = match_freq/1000000\n",
    "                    if (predicted.detach().cpu().numpy() == 2):\n",
    "                        c2 = c2 + 1\n",
    "                        freq_histo[j] = match_freq/1000000\n",
    "                    if (predicted.detach().cpu().numpy() == 3):\n",
    "                        c3 = c3 + 1\n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 4):\n",
    "                        c4 = c4 + 1\n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 5):\n",
    "                        c5 = c5 + 1 \n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 6):\n",
    "                        c6 = c6 + 1 \n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 7):\n",
    "                        c7 = c7 + 1 \n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 8):\n",
    "                        noise = noise + 1\n",
    "                    if (predicted.detach().cpu().numpy() == 9):\n",
    "                        center_fft = center_fft + 1  \n",
    "                    if (predicted.detach().cpu().numpy() == 10):\n",
    "                        c8 = c8 + 1  \n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    if (predicted.detach().cpu().numpy() == 11):\n",
    "                        c9 = c9 + 1 \n",
    "                        freq_histo[j] = match_freq/1000000            \n",
    "                    freq_offset = freq_offset + 1\n",
    "                    if (freq_offset == seg_freq):\n",
    "                        freq_offset = 0\n",
    "                    match_freq = start_frequency\n",
    "                torch.cuda.empty_cache()\n",
    "                # complete ******************************************************\n",
    "                freq_histo = np.ma.masked_equal(freq_histo, 0)\n",
    "                histo_stats_freq_file(freq_histo,msps)\n",
    "                denom = total-center_fft-noise\n",
    "                print('************************* Probabilities ********************************')\n",
    "                print('----------------------------WAVEFORMS-----------------------------------')\n",
    "                if (denom == 0):\n",
    "                    print('Nothing but noise')\n",
    "                else:\n",
    "                    print('LoRa 125 = {:.2f}%'.format(c0/denom*100))\n",
    "                    print('GD55 DMR = {:.2f}%'.format(c1/denom*100))\n",
    "                    print('NFM = {:.2f}%'.format(c2/denom*100))\n",
    "                    print('TYT = {:.2f}'.format(c3/denom*100))\n",
    "                    print('Vodeson Doorbell = {:.2f}%'.format(c4/denom*100))\n",
    "                    print('clickndig = {:.2f}%'.format(c5/denom*100))\n",
    "                    print('Sado doorbell = {:.2f}%'.format(c6/denom*100))\n",
    "                    print('LoRa 250 = {:.2f}%'.format(c7/denom*100))\n",
    "                    print('light switch = {:.2f}%'.format(c8/denom*100))\n",
    "                    print('YSF = {:.2f}%'.format(c9/denom*100))\n",
    "                print('------------------------------------------------------------------------')\n",
    "                print('***************************** noise and fft ****************************')\n",
    "                print('noise matches = ', noise)\n",
    "                print('center fft matches = ', center_fft)\n",
    "                print('TOTAL patch count = ', total)\n",
    "                print('***************************** Finished *********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_IQ_data_files(center_freq_file, list_of_IQ_data, list_of_labels,load_net):    \n",
    "    with torch.no_grad():\n",
    "        model = load_model(load_net)\n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        histogram_global = {}\n",
    "        histogram_data = np.zeros((10,10))\n",
    "        h = 0\n",
    "        for data in list_of_IQ_data:\n",
    "            histogram = np.zeros(12)\n",
    "            # chop \"data\" into the required patch size\n",
    "            frequency, time, dims1 = data.shape\n",
    "            list_of_patches = []\n",
    "            seg_t = 224  \n",
    "            seg_f = 224 \n",
    "            seg_time = time//seg_t\n",
    "            seg_freq = frequency//seg_f\n",
    "            # Segment the time axis\n",
    "            for j in range(seg_time): \n",
    "                    # Segment the frequency axis\n",
    "                    for k in range(seg_freq): \n",
    "                        IQ = data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                        list_of_patches.append(IQ)   \n",
    "#***************************************************************************************************************                        \n",
    "            start_frequency = (center_freq_file)\n",
    "            match_freq = start_frequency   \n",
    "            print('start_frequency = ', start_frequency/1000000)           \n",
    "            # loop through each square  in list_of_patches and score each\n",
    "            freq_increment = (Fs*msps/2)/seg_freq\n",
    "            histogram_frequency = np.zeros(len(list_of_patches))\n",
    "            denom = len(list_of_patches)\n",
    "            print('patch total = ', denom)\n",
    "            count_noise = 0\n",
    "            count_center = 0\n",
    "            freq_histo = np.zeros(len(list_of_patches))\n",
    "            freq_count = 0 # keep track of array position\n",
    "            freq_offset = 0\n",
    "            for (j, patch) in enumerate(list_of_patches):\n",
    "                num_correct, accuracy = 0, 0\n",
    "                patch = torch.Tensor(patch) # convert path to tensor\n",
    "                patch = patch.unsqueeze(0) # give the patch a fake batch axis\n",
    "                patch = patch.permute(0,3,1,2) # move the channel axis to the front\n",
    "                patch = patch.contiguous().cuda(GPU) # move the tensor to GPU     \n",
    "                outputs = model(patch)\n",
    "                predicted_class = int(torch.argmax(outputs.data))\n",
    "                histogram[predicted_class] += 1\n",
    "                histogram_global[predicted_class] = histogram_global.get(predicted_class, 0) + 1\n",
    "                if predicted_class == 8:\n",
    "                    count_noise += 1\n",
    "                if predicted_class == 9:\n",
    "                    count_center += 1\n",
    "                match_freq = match_freq + freq_offset*freq_increment\n",
    "#*******************************************************************************   \n",
    "                if (predicted_class == 0):\n",
    "                    freq_histo[j] = match_freq/1000000\n",
    "                if (predicted_class == 1):\n",
    "                    freq_histo[j] = match_freq/1000000\n",
    "                if (predicted_class == 2):\n",
    "                    freq_histo[j] = match_freq/1000000\n",
    "                if (predicted_class == 3):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 4):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 5):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 6):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 7):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 10):\n",
    "                    freq_histo[j] = match_freq/1000000            \n",
    "                if (predicted_class == 11):\n",
    "                    freq_histo[j] = match_freq/1000000                   \n",
    "#******************************************************************************\n",
    "                histogram_frequency[j] = match_freq/1000000\n",
    "                freq_offset = freq_offset + 1\n",
    "                if (freq_offset == seg_freq):\n",
    "                    freq_offset = 0\n",
    "                match_freq = start_frequency                \n",
    "            # print statistics\n",
    "            denom = denom - count_noise - count_center\n",
    "            histo_stats_freq_file(freq_histo, msps)\n",
    "            print('************************* Probabilities ********************************')\n",
    "            print('----------------------------WAVEFORMS-----------------------------------')\n",
    "            if (denom == 0):\n",
    "                print('Nothing but noise')\n",
    "            else:\n",
    "                print('LoRa 125 = {:.2f}%'.format(histogram[0]/denom))\n",
    "                print('GD55 DMR = {:.2f}%'.format(histogram[1]/denom))\n",
    "                print('NFM = {:.2f}%'.format(histogram[2]/denom))\n",
    "                print('TYT = {:.2f}'.format(histogram[3]/denom))\n",
    "                print('Vodeson Doorbell = {:.2f}%'.format(histogram[4]/denom))\n",
    "                print('clickndig = {:.2f}%'.format(histogram[5]/denom))\n",
    "                print('Sado doorbell = {:.2f}%'.format(histogram[6]/denom))\n",
    "                print('LoRa 250 = {:.2f}%'.format(histogram[7]/denom))\n",
    "                print('light switch = {:.2f}%'.format(histogram[10]/denom))\n",
    "                print('YSF = {:.2f}%'.format(histogram[11]/denom))\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print('***************************** noise and fft ****************************')\n",
    "            print('noise matches = ', count_noise)\n",
    "            print('center fft matches = ', count_center)\n",
    "            print('TOTAL patch count = ', len(list_of_patches))\n",
    "            print('***************************** Finished *********************************')\n",
    "            histogram_data[h,0] = histogram[0]/denom\n",
    "            histogram_data[h,1] = histogram[1]/denom\n",
    "            histogram_data[h,2] = histogram[2]/denom\n",
    "            histogram_data[h,3] = histogram[3]/denom\n",
    "            histogram_data[h,4] = histogram[4]/denom\n",
    "            histogram_data[h,5] = histogram[5]/denom\n",
    "            histogram_data[h,6] = histogram[6]/denom\n",
    "            histogram_data[h,7] = histogram[7]/denom\n",
    "            histogram_data[h,8] = histogram[10]/denom   \n",
    "            histogram_data[h,9] = histogram[11]/denom                       \n",
    "            h = h + 1\n",
    "    return histogram_global, histogram_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_live(center_freq_file, data_file, label_vector,load_net):    \n",
    "    with torch.no_grad():\n",
    "        model = load_model2(load_net)\n",
    "        total_ground_truth_count = 0\n",
    "        ground_truth_count = 0\n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = 0  \n",
    "        lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "        T0_lora125 = T1_gd55 = T2_nfm = T3_tyt = T4_vod = T5_click = T6_sado = T7_lora250 = 0\n",
    "        T8_noise = T9_fft = T10_light = T11_ysf = 0\n",
    "        noise_class = [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]\n",
    "        histogram_global = {}\n",
    "        histogram_data = np.zeros((10,10))\n",
    "#         data = iq_read_test_live(data_file,msps)\n",
    "        data = iq_read_test_live_combine(data_file,msps) # 20211025\n",
    "#         print('iq data shape = ', data.shape)   \n",
    "# *********************** Print out a patch to verify process ************************************\n",
    "#         stft_plot1 = 10*np.log10(np.abs(data[:,:,0].data.detach().cpu().numpy()+eps))\n",
    "#         plt.imshow(stft_plot1, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "#         plt.show()          \n",
    "# *************************************************************************************************          \n",
    "        histogram = np.zeros(12)\n",
    "        # chop \"data\" into the required patch size\n",
    "        frequency, time, dims1 = data.shape\n",
    "        list_of_patches = []\n",
    "        seg_t = 224  \n",
    "        seg_f = 224 \n",
    "        seg_time = time//seg_t\n",
    "        seg_freq = frequency//seg_f\n",
    "        # Segment the time axis\n",
    "        for j in range(seg_time): \n",
    "                # Segment the frequency axis\n",
    "                for k in range(seg_freq): \n",
    "#                     IQ = data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                    IQ = data[seg_f*k:seg_f*(1+k),seg_t*j:seg_t*(1+j)]\n",
    "#                     IQ = torch.flip(IQ, [0]) # flip patch: THIS SCREWS UP CLASSIFICATION SOMEWHAT\n",
    "# *********************** Print out a patch to verify process ************************************\n",
    "                    print('IQ shape = ', IQ.shape)\n",
    "                    stft_plot1 = 10*np.log10(np.abs(IQ[:,:,0].data.detach().cpu().numpy()+eps))\n",
    "                    plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "                    plt.show()          \n",
    "# *************************************************************************************************\n",
    "                    list_of_patches.append(IQ)   \n",
    "#***************************************************************************************************************                        \n",
    "        freq_offset = 0                  \n",
    "        start_frequency = (center_freq_live)\n",
    "        match_freq = start_frequency   \n",
    "#         print('start_frequency = ', start_frequency/1000000)           \n",
    "        # loop through each square  in list_of_patches and score each\n",
    "        freq_increment = (Fs*msps/2)/seg_freq\n",
    "        histogram_frequency = np.zeros(len(list_of_patches))\n",
    "        denom = len(list_of_patches)\n",
    "        count_noise = 0\n",
    "        count_center = 0\n",
    "        freq_histo = np.zeros(len(list_of_patches))\n",
    "        freq_count = 0 # keep track of array position\n",
    "        for (j, patch) in enumerate(list_of_patches):\n",
    "            num_correct, accuracy = 0, 0\n",
    "#                 patch = torch.Tensor(patch) # already a tensor on GPU 20210610 *******\n",
    "            patch = patch.unsqueeze(0) # give the patch a fake batch axis\n",
    "            patch = patch.permute(0,3,1,2) # move the channel axis to the front\n",
    "            patch = patch.float() # convert patch to a float\n",
    "#                 patch = patch.contiguous().cuda(GPU) # move the tensor to GPU  # already on GPU 20210610 \n",
    "            outputs_logits, outputs_sig = model(patch)\n",
    "#             outputs_sig1 = torch.zeros(outputs_sig.shape)\n",
    "#             outputs_sig1[(torch.arange(len(outputs_sig)).unsqueeze(1), torch.topk(outputs_sig,2).indices)] = 1\n",
    "#             print('predicted classes = ', outputs_sig1)\n",
    "#             print('predicted sigmoid = ', torch.round(outputs_sig))\n",
    "#             print('ground truth      = ', label_vector)\n",
    "            predicted_sigmoid = torch.round(outputs_sig)\n",
    "            \n",
    "                # *********************** Print out a patch to verify process **************************\n",
    "#             if (np.invert(np.equal(predicted_sigmoid.detach().cpu().numpy(), noise_class).all())):\n",
    "#                 stft_plot1 = np.squeeze(patch, axis=0)\n",
    "#                 stft_plot1 =  10*np.log10(np.abs(stft_plot1[0, :, :].data.detach().cpu().numpy()+eps))\n",
    "#                 plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#                 plt.show()\n",
    "#                 print('outputs sigmoid =', outputs_sig)\n",
    "#                 print('predicted rounded =', predicted_sigmoid)\n",
    "                # **************************************************************************************    \n",
    "            label_test = torch.bitwise_and(torch.from_numpy(label_vector).long(),torch.round(outputs_sig).long().cpu())\n",
    "            label_test1 = label_test.type(torch.uint8)\n",
    "            if label_test1.any()==True:\n",
    "                ground_truth_count +=1\n",
    "            L0,L1,L2,L3,L4,L5,L6,L7,L8,L9,L10,L11 = count_classes_noprint(predicted_sigmoid)\n",
    "            T0,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11 = count_truth(label_test.int())\n",
    "            lora125 = lora125+L0\n",
    "            gd55 = gd55+L1\n",
    "            nfm = nfm+L2\n",
    "            tyt = tyt+L3\n",
    "            vod = vod+L4\n",
    "            click = click+L5\n",
    "            sado = sado+L6\n",
    "            lora250 = lora250+L7\n",
    "            noise = noise+L8\n",
    "            fft = fft+L9\n",
    "            light = light+L10\n",
    "            ysf = ysf+L11\n",
    "            #*****************************\n",
    "            T0_lora125 = T0_lora125+T0\n",
    "            T1_gd55 = T1_gd55+T1\n",
    "            T2_nfm = T2_nfm+T2\n",
    "            T3_tyt = T3_tyt+T3\n",
    "            T4_vod = T4_vod+T4\n",
    "            T5_click = T5_click+T5\n",
    "            T6_sado = T6_sado+T6\n",
    "            T7_lora250 = T7_lora250+T7\n",
    "            T8_noise = T8_noise+T8\n",
    "            T9_fft = T9_fft+T9\n",
    "            T10_light = T10_light+T10\n",
    "            T11_ysf = T11_ysf+T11\n",
    "#             outputs_logits = nn.functional.normalize(outputs_logits, p=2.0, dim=1, eps=1e-12, out=None)\n",
    "#             print('predicted logits = ', outputs_logits)\n",
    "#             _, predicted = torch.max(outputs_logits.data, 1) \n",
    "#                 print('Predicted class = ',predicted_class)\n",
    "#             predicted = int(predicted.detach().cpu().numpy())\n",
    "\n",
    "        results_count = truth_calc(T0_lora125,T1_gd55,T2_nfm,T3_tyt,T4_vod,T5_click,T6_sado,T7_lora250,T8_noise,T9_fft,T10_light,T11_ysf, label_vector)\n",
    "#         print('results count = ', results_count)\n",
    "#         print('ground truth count = ', ground_truth_count)\n",
    "#         print_totals(lora125,gd55,nfm,tyt,vod,click,sado,lora250,noise,fft,light,ysf) \n",
    "#         print('***************************************************************************')\n",
    "#         print('truth totals')\n",
    "#         print('***************************************************************************')\n",
    "#         print_totals(T0_lora125,T1_gd55,T2_nfm,T3_tyt,T4_vod,T5_click,T6_sado,T7_lora250,T8_noise,T9_fft,T10_light,T11_ysf) \n",
    "        torch.cuda.empty_cache() \n",
    "        return results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_live2(center_freq_file, data_file, folder_meta,load_net):    \n",
    "    print('testing_live2')\n",
    "    with torch.no_grad():\n",
    "        model = load_model2(load_net)\n",
    "        total_ground_truth_count = 0\n",
    "        ground_truth_count = 0\n",
    "        total = noise = center_fft = target_to_int = accumulated_corrects = percent_correct = 0\n",
    "        c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = 0  \n",
    "        lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "        T0_lora125 = T1_gd55 = T2_nfm = T3_tyt = T4_vod = T5_click = T6_sado = T7_lora250 = 0\n",
    "        T8_noise = T9_fft = T10_light = T11_ysf = 0\n",
    "        noise_class = [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]\n",
    "        histogram_global = {}\n",
    "        histogram_data = np.zeros((10,10))\n",
    "#         data = iq_read_test_live(data_file,msps)\n",
    "        data = iq_read_test_live_combine(data_file,msps) # 20211025\n",
    "        print('iq data shape = ', data.shape)   \n",
    "# *********************** Print out a patch to verify process ************************************\n",
    "#         stft_plot1 = 10*np.log10(np.abs(data[:,:,0].data.detach().cpu().numpy()+eps))\n",
    "#         plt.imshow(stft_plot1, vmin=-70, vmax=5, aspect='auto', origin='lower')\n",
    "#         plt.show()          \n",
    "# *************************************************************************************************          \n",
    "        histogram = np.zeros(12)\n",
    "        # chop \"data\" into the required patch size\n",
    "        frequency, time, dims1 = data.shape\n",
    "        list_of_patches = []\n",
    "        seg_t = 224  \n",
    "        seg_f = 224 \n",
    "        seg_time = time//seg_t\n",
    "        seg_freq = frequency//seg_f\n",
    "        # Segment the time axis\n",
    "        for j in range(seg_time): \n",
    "                # Segment the frequency axis\n",
    "                for k in range(seg_freq): \n",
    "#                     IQ = data[seg_f*k:(seg_f)+seg_f*k,seg_t*j:(seg_t)+seg_t*j]\n",
    "                    IQ = data[seg_f*k:seg_f*(1+k),seg_t*j:seg_t*(1+j)]\n",
    "#                     IQ = torch.flip(IQ, [0]) # flip patch: THIS SCREWS UP CLASSIFICATION SOMEWHAT\n",
    "# *********************** Print out a patch to verify process ************************************\n",
    "#                     print('IQ shape = ', IQ.shape)\n",
    "#                     stft_plot1 = 10*np.log10(np.abs(IQ[:,:,0].data.detach().cpu().numpy()+eps))\n",
    "#                     plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "#                     plt.show()          \n",
    "# *************************************************************************************************\n",
    "                    list_of_patches.append(IQ)   \n",
    "#***************************************************************************************************************                        \n",
    "        freq_offset = 0                  \n",
    "        start_frequency = (center_freq_live)\n",
    "        match_freq = start_frequency   \n",
    "#         print('start_frequency = ', start_frequency/1000000)           \n",
    "        # loop through each square  in list_of_patches and score each\n",
    "        freq_increment = (Fs*msps/2)/seg_freq\n",
    "        histogram_frequency = np.zeros(len(list_of_patches))\n",
    "        denom = len(list_of_patches)\n",
    "        count_noise = 0\n",
    "        count_center = 0\n",
    "        freq_histo = np.zeros(len(list_of_patches))\n",
    "        freq_count = 0 # keep track of array position\n",
    "        for (j, patch) in enumerate(list_of_patches):\n",
    "            num_correct, accuracy = 0, 0\n",
    "#                 patch = torch.Tensor(patch) # already a tensor on GPU 20210610 *******\n",
    "            patch = patch.unsqueeze(0) # give the patch a fake batch axis\n",
    "            patch = patch.permute(0,3,1,2) # move the channel axis to the front\n",
    "            patch = patch.float() # convert patch to a float\n",
    "#                 patch = patch.contiguous().cuda(GPU) # move the tensor to GPU  # already on GPU 20210610 \n",
    "            outputs_logits, outputs_sig = model(patch)\n",
    "#             outputs_sig1 = torch.zeros(outputs_sig.shape)\n",
    "#             outputs_sig1[(torch.arange(len(outputs_sig)).unsqueeze(1), torch.topk(outputs_sig,2).indices)] = 1\n",
    "#             print('predicted classes = ', outputs_sig1)\n",
    "#             print('predicted sigmoid = ', torch.round(outputs_sig))\n",
    "#             print('ground truth      = ', label_vector)\n",
    "            predicted_sigmoid = torch.round(outputs_sig)\n",
    "            label_vector = multiclass_test2(folder_meta)\n",
    "                # *********************** Print out a patch to verify process **************************\n",
    "            if (np.invert(np.equal(predicted_sigmoid.detach().cpu().numpy(), noise_class).all())):\n",
    "                stft_plot1 = np.squeeze(patch, axis=0)\n",
    "                stft_plot1 =  10*np.log10(np.abs(stft_plot1[0, :, :].data.detach().cpu().numpy()+eps))\n",
    "                plt.imshow(stft_plot1, vmin=-70, vmax=5)\n",
    "                plt.show()\n",
    "#                 print('ground truth      = ', label_vector)\n",
    "#                 print('predicted rounded =', predicted_sigmoid)\n",
    "                # **************************************************************************************    \n",
    "            label_test = torch.bitwise_and(torch.from_numpy(label_vector).long(),torch.round(outputs_sig).long().cpu())\n",
    "            label_test1 = label_test.type(torch.uint8)\n",
    "            if label_test1.any()==True:\n",
    "                ground_truth_count +=1\n",
    "            L0,L1,L2,L3,L4,L5,L6,L7,L8,L9,L10,L11 = count_classes(predicted_sigmoid)\n",
    "            T0,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11 = count_truth(label_test.int())\n",
    "            lora125 = lora125+L0\n",
    "            gd55 = gd55+L1\n",
    "            nfm = nfm+L2\n",
    "            tyt = tyt+L3\n",
    "            vod = vod+L4\n",
    "            click = click+L5\n",
    "            sado = sado+L6\n",
    "            lora250 = lora250+L7\n",
    "            noise = noise+L8\n",
    "            fft = fft+L9\n",
    "            light = light+L10\n",
    "            ysf = ysf+L11\n",
    "            #*****************************\n",
    "            T0_lora125 = T0_lora125+T0\n",
    "            T1_gd55 = T1_gd55+T1\n",
    "            T2_nfm = T2_nfm+T2\n",
    "            T3_tyt = T3_tyt+T3\n",
    "            T4_vod = T4_vod+T4\n",
    "            T5_click = T5_click+T5\n",
    "            T6_sado = T6_sado+T6\n",
    "            T7_lora250 = T7_lora250+T7\n",
    "            T8_noise = T8_noise+T8\n",
    "            T9_fft = T9_fft+T9\n",
    "            T10_light = T10_light+T10\n",
    "            T11_ysf = T11_ysf+T11\n",
    "#             outputs_logits = nn.functional.normalize(outputs_logits, p=2.0, dim=1, eps=1e-12, out=None)\n",
    "#             print('predicted logits = ', outputs_logits)\n",
    "#             _, predicted = torch.max(outputs_logits.data, 1) \n",
    "#                 print('Predicted class = ',predicted_class)\n",
    "#             predicted = int(predicted.detach().cpu().numpy())\n",
    "\n",
    "        results_count = truth_calc(T0_lora125,T1_gd55,T2_nfm,T3_tyt,T4_vod,T5_click,T6_sado,T7_lora250,T8_noise,T9_fft,T10_light,T11_ysf, label_vector)\n",
    "#         print('results count = ', results_count)\n",
    "#         print('ground truth count = ', ground_truth_count)\n",
    "#         print_totals(lora125,gd55,nfm,tyt,vod,click,sado,lora250,noise,fft,light,ysf) \n",
    "#         print('***************************************************************************')\n",
    "#         print('truth totals')\n",
    "#         print('***************************************************************************')\n",
    "#         print_totals(T0_lora125,T1_gd55,T2_nfm,T3_tyt,T4_vod,T5_click,T6_sado,T7_lora250,T8_noise,T9_fft,T10_light,T11_ysf) \n",
    "        torch.cuda.empty_cache() \n",
    "        return results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_test2(folder_meta):\n",
    "    one_hot_label = np.zeros([12]).astype(int) # creating one hot vector\n",
    "    i = 0\n",
    "    for label_list in folder_meta:\n",
    "        with open(str(label_list)) as meta_data:\n",
    "            metadata = json.load(meta_data)\n",
    "            label = int(metadata[\"global\"][\"core:class\"])\n",
    "#                 print('label = ', label)\n",
    "        one_hot_label[label] = 1\n",
    "#     print(one_hot_label)\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_calc(T0,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11,label_vector):\n",
    "    results = 0\n",
    "    result_vector = np.zeros([12]).astype(int) # creating one hot vector\n",
    "    lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "#     label_vector = label_vector.int()\n",
    "#     label_test = torch.squeeze(label_vector)\n",
    "    if T0>=1:\n",
    "        result_vector[0]=1\n",
    "    if T1>=1:\n",
    "        result_vector[1]=1\n",
    "    if T2>=1:\n",
    "        result_vector[2]=1\n",
    "    if T3>=1:\n",
    "        result_vector[3]=1\n",
    "    if T4>=1:\n",
    "        result_vector[4]=1\n",
    "    if T5>=1:\n",
    "        result_vector[5]=1\n",
    "    if T6>=1:\n",
    "        result_vector[6]=1\n",
    "    if T7>=1:\n",
    "        result_vector[7]=1\n",
    "    if T8>=1:\n",
    "        result_vector[8]=1\n",
    "    if T9>=1:\n",
    "        result_vector[9]=1\n",
    "    if T10>=1:\n",
    "        result_vector[10]=1\n",
    "    if T11>=1:\n",
    "        result_vector[11]=1 \n",
    "#     print('label vector = ', label_vector.astype(int), type(label_vector))\n",
    "#     print('result vector = ', result_vector, type(result_vector))\n",
    "#     if np.bitwise_and(label_vector.astype(int),result_vector).all()==True:\n",
    "    if (label_vector.astype(int)==result_vector).all():    \n",
    "        results = 1\n",
    "#         print('result_vector = TRUE')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_truth(label_test):\n",
    "    lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "    label_test = label_test.int()\n",
    "    label_test = torch.squeeze(label_test)\n",
    "    if label_test[0]==1:\n",
    "#         print('LoRa 125')\n",
    "        lora125 = lora125+1\n",
    "    if label_test[1]==1:\n",
    "#         print('GD55')\n",
    "        gd55 = gd55+1\n",
    "    if label_test[2]==1:\n",
    "#         print('NFM')\n",
    "        nfm = nfm+1\n",
    "    if label_test[3]==1:\n",
    "#         print('TYT')\n",
    "        tyt = tyt+1\n",
    "    if label_test[4]==1:\n",
    "#         print('Vodeson')\n",
    "        vod = vod+1\n",
    "    if label_test[5]==1:\n",
    "#         print('clickndig')\n",
    "        click = click+1\n",
    "    if label_test[6]==1:\n",
    "#         print('Sado')\n",
    "        sado = sado+1\n",
    "    if label_test[7]==1:\n",
    "#         print('LoRa 250')\n",
    "        lora250 = lora250+1\n",
    "    if label_test[8]==1:\n",
    "#         print('noise')\n",
    "        noise = noise+1\n",
    "    if label_test[9]==1:\n",
    "#         print('fft')\n",
    "        fft=fft+1\n",
    "    if label_test[10]==1:\n",
    "#         print('light switch')\n",
    "        light = light+1\n",
    "    if label_test[11]==1:\n",
    "#         print('YSF')\n",
    "        ysf = ysf+1\n",
    "    return lora125, gd55, nfm, tyt, vod, click, sado, lora250, noise, fft, light, ysf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(pred_array):\n",
    "    lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "    pred_array = pred_array.int()\n",
    "    pred_array = torch.squeeze(pred_array)\n",
    "    if pred_array[0]==1:\n",
    "        print('LoRa 125')\n",
    "        lora125 = lora125+1\n",
    "    if pred_array[1]==1:\n",
    "        print('GD55')\n",
    "        gd55 = gd55+1\n",
    "    if pred_array[2]==1:\n",
    "        print('NFM')\n",
    "        nfm = nfm+1\n",
    "    if pred_array[3]==1:\n",
    "        print('TYT')\n",
    "        tyt = tyt+1\n",
    "    if pred_array[4]==1:\n",
    "        print('Vodeson')\n",
    "        vod = vod+1\n",
    "    if pred_array[5]==1:\n",
    "        print('clickndig')\n",
    "        click = click+1\n",
    "    if pred_array[6]==1:\n",
    "        print('Sado')\n",
    "        sado = sado+1\n",
    "    if pred_array[7]==1:\n",
    "        print('LoRa 250')\n",
    "        lora250 = lora250+1\n",
    "    if pred_array[8]==1:\n",
    "#         print('noise')\n",
    "        noise = noise+1\n",
    "    if pred_array[9]==1:\n",
    "#         print('fft')\n",
    "        fft=fft+1\n",
    "    if pred_array[10]==1:\n",
    "        print('light switch')\n",
    "        light = light+1\n",
    "    if pred_array[11]==1:\n",
    "        print('YSF')\n",
    "        ysf = ysf+1\n",
    "    return lora125, gd55, nfm, tyt, vod, click, sado, lora250, noise, fft, light, ysf            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes_noprint(pred_array):\n",
    "    lora125 = gd55 = nfm = tyt = vod = click = sado = lora250 = noise = fft = light = ysf = 0\n",
    "    pred_array = pred_array.int()\n",
    "    pred_array = torch.squeeze(pred_array)\n",
    "    if pred_array[0]==1:\n",
    "        lora125 = lora125+1\n",
    "    if pred_array[1]==1:\n",
    "        gd55 = gd55+1\n",
    "    if pred_array[2]==1:\n",
    "        nfm = nfm+1\n",
    "    if pred_array[3]==1:\n",
    "        tyt = tyt+1\n",
    "    if pred_array[4]==1:\n",
    "        vod = vod+1\n",
    "    if pred_array[5]==1:\n",
    "        click = click+1\n",
    "    if pred_array[6]==1:\n",
    "        sado = sado+1\n",
    "    if pred_array[7]==1:\n",
    "        lora250 = lora250+1\n",
    "    if pred_array[8]==1:\n",
    "        noise = noise+1\n",
    "    if pred_array[9]==1:\n",
    "        fft=fft+1\n",
    "    if pred_array[10]==1:\n",
    "        light = light+1\n",
    "        ysf = ysf+1\n",
    "    return lora125, gd55, nfm, tyt, vod, click, sado, lora250, noise, fft, light, ysf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_totals(lora125,gd55,nfm,tyt,vod,click,sado,lora250,noise,fft,light,ysf):\n",
    "    print('LoRa 125 = ', lora125)\n",
    "    print('GD55 = ', gd55)\n",
    "    print('NFM = ', nfm)\n",
    "    print('TYT = ', tyt)\n",
    "    print('Vodeson = ', vod)\n",
    "    print('ClicknDig = ', click)\n",
    "    print('Sado = ', sado)\n",
    "    print('LoRa 250 = ', lora250)\n",
    "    print('noise = ', noise)\n",
    "    print('FFT = ', fft)\n",
    "    print('Light switch = ', light)\n",
    "    print('YSF = ', ysf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original loader - used when not limiting training data size to batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_dataloader = RFDataset(path, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer = load_model()\n",
    "# CUDA = torch.cuda.is_available()\n",
    "# if CUDA:\n",
    "#     model.cuda(GPU)\n",
    "#     print('loaded to GPU')\n",
    "# CUDA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(4, 12) # number of input channels, number of classes\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model.cuda(GPU)\n",
    "CUDA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# lr= 1e-6 # .0004\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VALIDATION ************************************************************\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Class load and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batches = 64\n",
    "# train_dataloader = RFDataset(path, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patch_limit = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patch_limit)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total = 5\n",
    "# loss_plot,total_plot = train_net_clean(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi- Class load and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global batch variable needs to be doubled or tripled from clean training\n",
    "    1) must rerun training loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for 1 class per patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 64\n",
    "classes = 1\n",
    "batches = batches*classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr= 1e-4 # .0004\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperated dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataloader1 = RFDataset(path_1msps, limit=None)\n",
    "# train_dataloader25 = RFDataset(path_25msps, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader1 = RFDataset(path_1msps, limit=None)\n",
    "# train_dataloader25 = RFDataset(path_25msps, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = data.DataLoader(train_dataloader25, batch_size=batches, shuffle=True)\n",
    "# training_data25 = data.DataLoader(train_dataloader25, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combined dataloaders (External drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = RFDataset(path, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation dataloader setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patches = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patches)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_patches = None\n",
    "rf_dataset_val1 = RFDataset2(path_val_1msps, limit=val_patches)\n",
    "rf_dataset_val5 = RFDataset2(path_val_5msps, limit=val_patches)\n",
    "rf_dataset_val10 = RFDataset2(path_val_10msps, limit=val_patches)\n",
    "rf_dataset_val25 = RFDataset2(path_val_25msps, limit=val_patches)\n",
    "validation_data1 = data.DataLoader(rf_dataset_val1, batch_size=batches, shuffle=True)\n",
    "validation_data1 = [validation_data1]\n",
    "validation_data5 = data.DataLoader(rf_dataset_val5, batch_size=batches, shuffle=True)\n",
    "validation_data5 = [validation_data5]\n",
    "validation_data10 = data.DataLoader(rf_dataset_val10, batch_size=batches, shuffle=True)\n",
    "validation_data10 = [validation_data10]\n",
    "validation_data25 = data.DataLoader(rf_dataset_val25, batch_size=batches, shuffle=True)\n",
    "validation_data25 = [validation_data25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 20\n",
    "loss_plot, total_plot, plot_1msps, plot_5msps, plot_10msps, plot_25msps = train_net_combined_data(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING 1 class/patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "os.chdir(path_plot_fig)\n",
    "np.save('resnet18_total_plot_20220226_rev1_mix_msps', np.asarray(total_plot))\n",
    "np.save('resnet18_plot_1msps_20220226_rev1_mix_msps', np.asarray(plot_1msps))\n",
    "np.save('resnet18_plot_5msps_20220226_rev1_mix_msps', np.asarray(plot_5msps))\n",
    "np.save('resnet18_plot_10msps_20220226_rev1_mix_msps', np.asarray(plot_10msps))\n",
    "np.save('resnet18_plot_25msps_20220226_rev1_mix_msps', np.asarray(plot_25msps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "os.chdir(path_plot_fig)\n",
    "resnet50_total_plot = np.load('resnet18_total_plot_20220226_rev1_mix_msps.npy')\n",
    "resnet50_plot_1msps = np.load('resnet18_plot_1msps_20220226_rev1_mix_msps.npy')\n",
    "resnet50_plot_5msps = np.load('resnet18_plot_5msps_20220226_rev1_mix_msps.npy')\n",
    "resnet50_plot_10msps = np.load('resnet18_plot_10msps_20220226_rev1_mix_msps.npy')\n",
    "resnet50_plot_25msps = np.load('resnet18_plot_25msps_20220226_rev1_mix_msps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(resnet50_plot_1msps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_plot_25msps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kilo_samples(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    if x>=1000:\n",
    "        return '%1.1fk' % (x*1e-3)\n",
    "    return '%0d' % (x*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f907072fa58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatter = FuncFormatter(kilo_samples)\n",
    "lim1 = 1500\n",
    "a = np.arange(0,lim1,100) # Start at index position 1\n",
    "lim2 = 300000\n",
    "b = np.arange(1500,lim2,1000) # Start at index position 1\n",
    "x = np.concatenate((a, b), axis=0)\n",
    "a = 0\n",
    "# num = 125\n",
    "num = 25\n",
    "# x = np.arange(0,num,1) # Start at index position 1\n",
    "plt.rcParams.update({'font.size': 23})\n",
    "# plt.figure(figsize=(9, 6))\n",
    "\n",
    "# fig2 = plt.figure()\n",
    "\n",
    "fig2, ax = plt.subplots()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "\n",
    "\n",
    "# ax = plt.subplot(111)\n",
    "# Shrink current axis by 20%\n",
    "# box = ax.get_position()\n",
    "# ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "plt.plot(x[a:num],resnet50_plot_1msps[a:num], '-*', c='darkblue',markersize=6, linewidth=2,markerfacecolor='darkblue',markeredgecolor='darkblue',markeredgewidth=2, label='1')\n",
    "plt.plot(x[a:num],resnet50_plot_5msps[a:num], '-X', c='blue', markersize=6, linewidth=2,markerfacecolor='blue',markeredgecolor='blue',markeredgewidth=2, label='5')\n",
    "plt.plot(x[a:num],resnet50_plot_10msps[a:num], '-D', c='red', markersize=6, linewidth=2,markerfacecolor='red',markeredgecolor='red',markeredgewidth=2, label='10')\n",
    "plt.plot(x[a:num],resnet50_plot_25msps[a:num], '-^', c='darkred', markersize=6, linewidth=2,markerfacecolor='darkred',markeredgecolor='darkred',markeredgewidth=2, label='25')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "# Put a legend to the right of the current axis\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Validation: 1 and 25 MSPS', fontsize=23)\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.5,1, .1))\n",
    "# plt.yticks([.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "plt.yticks([.3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "# plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 10])\n",
    "# plt.xticks([100, 10000,20000, 30000])\n",
    "plt.xticks([100, 5000,10000])\n",
    "# plt.tight_layout()\n",
    "axes=plt.gca()\n",
    "# ax.set_aspect('equal')\n",
    "# axes.set_aspect(10)\n",
    "plt.subplots_adjust(left=0.17)\n",
    "plt.subplots_adjust(bottom=0.20)\n",
    "# fig2.set_size_inches(8.27, 11.69)\n",
    "fig2.set_size_inches(6.0, 4.0)\n",
    "fig2.savefig('resnet18_1class_20220227_mix_msps.pdf', format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original plot used in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = len(resnet50_4D) # reduced rank by 1 for matrix math to work out\n",
    "num = 9\n",
    "x = np.arange(0,num,1) # Start at index position 1\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "# plt.figure(figsize=(9, 6))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "# ax = plt.subplot(111)\n",
    "# Shrink current axis by 20%\n",
    "# box = ax.get_position()\n",
    "# ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "plt.plot(x[1:num],resnet50_plot_1msps[1:num], '-*', c='darkblue',markersize=6, linewidth=2,markerfacecolor='darkblue',markeredgecolor='darkblue',markeredgewidth=2, label='1')\n",
    "plt.plot(x[1:num],resnet50_plot_5msps[1:num], '-X', c='blue', markersize=6, linewidth=2,markerfacecolor='blue',markeredgecolor='blue',markeredgewidth=2, label='5')\n",
    "plt.plot(x[1:num],resnet50_plot_10msps[1:num], '-D', c='red', markersize=6, linewidth=2,markerfacecolor='red',markeredgecolor='red',markeredgewidth=2, label='10')\n",
    "plt.plot(x[1:num],resnet50_plot_25msps[1:num], '-^', c='darkred', markersize=6, linewidth=2,markerfacecolor='darkred',markeredgecolor='darkred',markeredgewidth=2, label='25')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "# Put a legend to the right of the current axis\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Validation: 1 & 25MSPS', fontsize=13)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.5,1, .1))\n",
    "plt.yticks([.2, .4, .6, .8, 1.0])\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "# plt.tight_layout()\n",
    "axes=plt.gca()\n",
    "axes.set_aspect(7)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.subplots_adjust(bottom=0.20)\n",
    "fig2.set_size_inches(6.0, 4.0)\n",
    "fig2.savefig('resnet50_mix_1class_20220125_old.pdf', format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training 2 classes per patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 64\n",
    "classes = 2\n",
    "batches = batches*classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr= 1e-4 # .0004\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperated dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader1 = RFDataset(path_1msps, limit=None)\n",
    "# train_dataloader25 = RFDataset(path_25msps, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data1 = data.DataLoader(train_dataloader1, batch_size=batches, shuffle=True)\n",
    "# training_data25 = data.DataLoader(train_dataloader25, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combined dataloaders (External drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = RFDataset(path, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patches = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patches)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patches = None\n",
    "rf_dataset_val1 = RFDataset(path_val_1msps, limit=val_patches)\n",
    "rf_dataset_val5 = RFDataset(path_val_5msps, limit=val_patches)\n",
    "rf_dataset_val10 = RFDataset(path_val_10msps, limit=val_patches)\n",
    "rf_dataset_val25 = RFDataset(path_val_25msps, limit=val_patches)\n",
    "validation_data1 = data.DataLoader(rf_dataset_val1, batch_size=batches, shuffle=True)\n",
    "validation_data1 = [validation_data1]\n",
    "validation_data5 = data.DataLoader(rf_dataset_val5, batch_size=batches, shuffle=True)\n",
    "validation_data5 = [validation_data5]\n",
    "validation_data10 = data.DataLoader(rf_dataset_val10, batch_size=batches, shuffle=True)\n",
    "validation_data10 = [validation_data10]\n",
    "validation_data25 = data.DataLoader(rf_dataset_val25, batch_size=batches, shuffle=True)\n",
    "validation_data25 = [validation_data25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 20\n",
    "loss_plot2, total_plot2, plot_1msps2, plot_5msps2, plot_10msps2, plot_25msps2 = train_net_combined_data(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_plot_1msps2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING 2 classes/patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "os.chdir(path_plot_fig)\n",
    "# np.save('resnet50_4ch_total_plot2_20220211', np.asarray(total_plot2))\n",
    "np.save('resnet50_4ch_plot_1msps2_20220211', np.asarray(plot_1msps2))\n",
    "np.save('resnet50_4ch_plot_5msps2_20220211', np.asarray(plot_5msps2))\n",
    "np.save('resnet50_4ch_plot_10msps2_20220211', np.asarray(plot_10msps2))\n",
    "np.save('resnet50_4ch_plot_25msps2_20220211', np.asarray(plot_25msps2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "os.chdir(path_plot_fig)\n",
    "# resnet50_total_plot2 = np.load('resnet50_4ch_total_plot2_20220211.npy')\n",
    "resnet50_plot_1msps2 = np.load('resnet50_4ch_plot_1msps2_20220211.npy')\n",
    "resnet50_plot_5msps2 = np.load('resnet50_4ch_plot_5msps2_20220211.npy')\n",
    "resnet50_plot_10msps2 = np.load('resnet50_4ch_plot_10msps2_20220211.npy')\n",
    "resnet50_plot_25msps2 = np.load('resnet50_4ch_plot_25msps2_20220211.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formatter = FuncFormatter(kilo_samples)\n",
    "lim1 = 1500\n",
    "a = np.arange(0,lim1,100) # Start at index position 1\n",
    "lim2 = 100000\n",
    "b = np.arange(1500,lim2,1000) # Start at index position 1\n",
    "x = np.concatenate((a, b), axis=0)\n",
    "a = 0\n",
    "num = 69\n",
    "# x = np.arange(0,num,1) # Start at index position 1\n",
    "plt.rcParams.update({'font.size': 23})\n",
    "fig2, ax = plt.subplots()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.plot(x[a:num],resnet50_plot_1msps2[a:num], '-*', c='darkblue',markersize=6, linewidth=2,markerfacecolor='darkblue',markeredgecolor='darkblue',markeredgewidth=2, label='1')\n",
    "plt.plot(x[a:num],resnet50_plot_5msps2[a:num], '-X', c='blue', markersize=6, linewidth=2,markerfacecolor='blue',markeredgecolor='blue',markeredgewidth=2, label='5')\n",
    "plt.plot(x[a:num],resnet50_plot_10msps2[a:num], '-D', c='red', markersize=6, linewidth=2,markerfacecolor='red',markeredgecolor='red',markeredgewidth=2, label='10')\n",
    "plt.plot(x[a:num],resnet50_plot_25msps2[a:num], '-^', c='darkred', markersize=6, linewidth=2,markerfacecolor='darkred',markeredgecolor='darkred',markeredgewidth=2, label='25')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "# Put a legend to the right of the current axis\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Validation: 2 classes/patch', fontsize=23)\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.5,1, .1))\n",
    "# plt.yticks([.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "plt.yticks([.3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "# plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 10])\n",
    "plt.xticks([100, 20000, 55000])\n",
    "# plt.tight_layout()\n",
    "axes=plt.gca()\n",
    "# ax.set_aspect('equal')\n",
    "# axes.set_aspect(10)\n",
    "plt.subplots_adjust(left=0.17)\n",
    "plt.subplots_adjust(bottom=0.20)\n",
    "# fig2.set_size_inches(8.27, 11.69)\n",
    "fig2.set_size_inches(6.0, 4.0)\n",
    "fig2.savefig('resnet50_2classes_20220210.pdf', format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original 2 class/patch plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = len(resnet50_4D) # reduced rank by 1 for matrix math to work out\n",
    "num = 20\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "x = np.arange(0,num,1) # Start at index position 1\n",
    "# plt.figure(figsize=(9, 6))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# plt.plot(x[0:num],resnet50_total_plot2[:num], '-o', c='#1f77b4',markersize=6, linewidth=2,markerfacecolor='#1f77b4',markeredgecolor='#1f77b4',markeredgewidth=2,label='total')\n",
    "plt.plot(x[1:num],resnet50_plot_1msps2[1:num], '-*', c='#ff7f0e',markersize=6, linewidth=2,markerfacecolor='#ff7f0e',markeredgecolor='#ff7f0e',markeredgewidth=2, label='1')\n",
    "plt.plot(x[1:num],resnet50_plot_5msps2[1:num], '-X', c='#2ca02c', markersize=6, linewidth=2,markerfacecolor='#2ca02c',markeredgecolor='#2ca02c',markeredgewidth=2, label='5')\n",
    "plt.plot(x[1:num],resnet50_plot_10msps2[1:num], '-D', c='#d62728', markersize=6, linewidth=2,markerfacecolor='#d62728',markeredgecolor='#d62728',markeredgewidth=2, label='10')\n",
    "plt.plot(x[1:num],resnet50_plot_25msps2[1:num], '-^', c='#9467bd', markersize=6, linewidth=2,markerfacecolor='#9467bd',markeredgecolor='#9467bd',markeredgewidth=2, label='25')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.legend(loc='center right')\n",
    "plt.title('Validation accuracy 2 classes/patch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.1,1, .1))\n",
    "plt.yticks([.3, .4,.5, .6, .7, .8, .9, 1.0])\n",
    "plt.xticks([0, 1, 3, 5, 7, 9, 11,13,15,17,19])\n",
    "fig2.savefig('resnet50_4ch_20211223_2classes.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for 3 classes per patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 64\n",
    "classes = 3\n",
    "batches = batches*classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr= 1e-4 # .0004\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperated dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader1 = RFDataset(path_1msps, limit=None)\n",
    "# train_dataloader25 = RFDataset(path_25msps, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data1 = data.DataLoader(train_dataloader1, batch_size=batches, shuffle=True)\n",
    "# training_data25 = data.DataLoader(train_dataloader25, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combined dataloaders (External drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = RFDataset(path, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.DataLoader(train_dataloader, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_patches = None\n",
    "# rf_dataset_val = RFDataset(path_validation, limit=val_patches)\n",
    "# validation_data = data.DataLoader(rf_dataset_val, batch_size=batches, shuffle=True)\n",
    "# validation_data = [validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patches = None\n",
    "rf_dataset_val1 = RFDataset(path_val_1msps, limit=val_patches)\n",
    "rf_dataset_val5 = RFDataset(path_val_5msps, limit=val_patches)\n",
    "rf_dataset_val10 = RFDataset(path_val_10msps, limit=val_patches)\n",
    "rf_dataset_val25 = RFDataset(path_val_25msps, limit=val_patches)\n",
    "validation_data1 = data.DataLoader(rf_dataset_val1, batch_size=batches, shuffle=True)\n",
    "validation_data1 = [validation_data1]\n",
    "validation_data5 = data.DataLoader(rf_dataset_val5, batch_size=batches, shuffle=True)\n",
    "validation_data5 = [validation_data5]\n",
    "validation_data10 = data.DataLoader(rf_dataset_val10, batch_size=batches, shuffle=True)\n",
    "validation_data10 = [validation_data10]\n",
    "validation_data25 = data.DataLoader(rf_dataset_val25, batch_size=batches, shuffle=True)\n",
    "validation_data25 = [validation_data25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 40\n",
    "loss_plot3, total_plot3, plot_1msps3, plot_5msps3, plot_10msps3, plot_25msps3 = train_net_combined_data(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING 3 classes/patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot_fig = \"/home/david/sigMF_ML/RF/RF_class/plot_data/\" # ACE\n",
    "os.chdir(path_plot_fig)\n",
    "np.save('resnet50_sub_epoch_total_plot3_2022211', np.asarray(total_plot3))\n",
    "np.save('resnet50_sub_epoch_plot_1msps3_2022211', np.asarray(plot_1msps3))\n",
    "np.save('resnet50_sub_epoch_plot_5msps3_2022211', np.asarray(plot_5msps3))\n",
    "np.save('resnet50_sub_epoch_plot_10msps3_2022211', np.asarray(plot_10msps3))\n",
    "np.save('resnet50_sub_epoch_plot_25msps3_2022211', np.asarray(plot_25msps3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_plot_fig)\n",
    "resnet50_total_plot3 = np.load('resnet50_sub_epoch_total_plot3_2022211.npy')\n",
    "resnet50_plot_1msps3 = np.load('resnet50_sub_epoch_plot_1msps3_2022211.npy')\n",
    "resnet50_plot_5msps3 = np.load('resnet50_sub_epoch_plot_5msps3_2022211.npy')\n",
    "resnet50_plot_10msps3 = np.load('resnet50_sub_epoch_plot_10msps3_2022211.npy')\n",
    "resnet50_plot_25msps3 = np.load('resnet50_sub_epoch_plot_25msps3_2022211.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "88-36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = FuncFormatter(kilo_samples)\n",
    "lim1 = 1500\n",
    "a = np.arange(0,lim1,100) # Start at index position 1\n",
    "lim2 = 100000\n",
    "b = np.arange(1500,lim2,1000) # Start at index position 1\n",
    "x = np.concatenate((a, b), axis=0)\n",
    "a = 55\n",
    "num = 75 #88\n",
    "# x = np.arange(0,num,1) # Start at index position 1\n",
    "plt.rcParams.update({'font.size': 23})\n",
    "fig2, ax = plt.subplots()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.plot(x[a:num],resnet50_plot_1msps3[a:num], '-*', c='darkblue',markersize=6, linewidth=2,markerfacecolor='darkblue',markeredgecolor='darkblue',markeredgewidth=2, label='1')\n",
    "plt.plot(x[a:num],resnet50_plot_5msps3[a:num], '-X', c='blue', markersize=6, linewidth=2,markerfacecolor='blue',markeredgecolor='blue',markeredgewidth=2, label='5')\n",
    "plt.plot(x[a:num],resnet50_plot_10msps3[a:num], '-D', c='red', markersize=6, linewidth=2,markerfacecolor='red',markeredgecolor='red',markeredgewidth=2, label='10')\n",
    "plt.plot(x[a:num],resnet50_plot_25msps3[a:num], '-^', c='darkred', markersize=6, linewidth=2,markerfacecolor='darkred',markeredgecolor='darkred',markeredgewidth=2, label='25')\n",
    "# plt.legend(loc='lower right', fontsize=13)\n",
    "# Put a legend to the right of the current axis\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Validation: 3 classes/patch', fontsize=23)\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.5,1, .1))\n",
    "# plt.yticks([.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "plt.yticks([.3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "# plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 10])\n",
    "# plt.xticks([100, 2000,4000, 8500])\n",
    "# plt.tight_layout()\n",
    "axes=plt.gca()\n",
    "# ax.set_aspect('equal')\n",
    "# axes.set_aspect(10)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.subplots_adjust(bottom=0.20)\n",
    "# fig2.set_size_inches(8.27, 11.69)\n",
    "fig2.set_size_inches(6.0, 4.0)\n",
    "fig2.savefig('resnet50_3classes_20220211.pdf', format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original 3 classes / patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = len(resnet50_4D) # reduced rank by 1 for matrix math to work out\n",
    "num = 30\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "x = np.arange(0,num,1) # Start at index position 1\n",
    "# plt.figure(figsize=(9, 6))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# plt.plot(x[0:num],resnet50_total_plot3[:num], '-o', c='#1f77b4',markersize=6, linewidth=2,markerfacecolor='#1f77b4',markeredgecolor='#1f77b4',markeredgewidth=2,label='total')\n",
    "plt.plot(x[1:num],resnet50_plot_1msps3[1:num], '-*', c='#ff7f0e',markersize=6, linewidth=2,markerfacecolor='#ff7f0e',markeredgecolor='#ff7f0e',markeredgewidth=2, label='1')\n",
    "plt.plot(x[1:num],resnet50_plot_5msps3[1:num], '-X', c='#2ca02c', markersize=6, linewidth=2,markerfacecolor='#2ca02c',markeredgecolor='#2ca02c',markeredgewidth=2, label='5')\n",
    "plt.plot(x[1:num],resnet50_plot_10msps3[1:num], '-D', c='#d62728', markersize=6, linewidth=2,markerfacecolor='#d62728',markeredgecolor='#d62728',markeredgewidth=2, label='10')\n",
    "plt.plot(x[1:num],resnet50_plot_25msps3[1:num], '-^', c='#9467bd', markersize=6, linewidth=2,markerfacecolor='#9467bd',markeredgecolor='#9467bd',markeredgewidth=2, label='25')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.legend(loc='center right')\n",
    "plt.title('Validation accuracy 3 classes/patch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% accuracy')\n",
    "plt.grid()\n",
    "# plt.minorticks_on()\n",
    "# plt.yticks(np.arange(.1,1, .1))\n",
    "plt.yticks([.3, .4, .5, .6, .7, .8, .9, 1.0])\n",
    "plt.xticks([0, 1, 3, 5, 7, 9, 11,13,15,17,19,21,23,25,27,29])\n",
    "fig2.savefig('resnet50_4ch_20211224_3classes.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing test file combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_10msps = \"/media/david/Elements/sigMF_ML/RF/10msps_sample_test/\" # multiclass testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_1msps = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_1msps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_1msps_compact = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_1msps_compact/\"\n",
    "path_test_5msps_compact = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_5msps_compact/\"\n",
    "path_test_10msps_compact = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_10msps_compact/\"\n",
    "path_test_25msps_compact = \"/media/david/Elements/sigMF_ML/RF/RF_class/testing_data_25msps_compact/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination testing script 20211108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_test(folder_meta):\n",
    "    one_hot_label = np.zeros([12]).astype(int) # creating one hot vector\n",
    "    i = 0\n",
    "    for label_list in folder_meta:\n",
    "        for label_path in label_list:\n",
    "            with open(str(label_path)) as meta_data:\n",
    "                metadata = json.load(meta_data)\n",
    "                label = int(metadata[\"global\"][\"core:class\"])\n",
    "#                 print('label = ', label)\n",
    "            one_hot_label[label] = 1\n",
    "#     print(one_hot_label)\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "k = 3\n",
    "scipy.special.comb(N, k).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 1\n",
    "N_choose_K = 3\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_1msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "folder_iq = [[],[],[]]\n",
    "folder_meta = [[],[],[]]\n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 5\n",
    "N_choose_K = 3\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_5msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "folder_iq = [[],[],[]]\n",
    "folder_meta = [[],[],[]]\n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 10\n",
    "N_choose_K = 3\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_10msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "folder_iq = [[],[],[]]\n",
    "folder_meta = [[],[],[]]\n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msps = 25\n",
    "N_choose_K = 3\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_25msps_compact).glob('*/'))\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "i = 0\n",
    "j= 0\n",
    "folder_iq = [[],[],[]]\n",
    "folder_meta = [[],[],[]]\n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 1\n",
    "N_choose_K = 2\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_1msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "if (N_choose_K==3):\n",
    "    folder_iq = [[],[],[]]\n",
    "    folder_meta = [[],[],[]]\n",
    "if (N_choose_K==2):\n",
    "    folder_iq = [[],[]]\n",
    "    folder_meta = [[],[]]    \n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         print('iq = ', folder_iq[i])\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "#         print('meta = ', folder_meta[i])\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 5\n",
    "N_choose_K = 2\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_5msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "if (N_choose_K==3):\n",
    "    folder_iq = [[],[],[]]\n",
    "    folder_meta = [[],[],[]]\n",
    "if (N_choose_K==2):\n",
    "    folder_iq = [[],[]]\n",
    "    folder_meta = [[],[]]  \n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 10\n",
    "N_choose_K = 2\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_10msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "if (N_choose_K==3):\n",
    "    folder_iq = [[],[],[]]\n",
    "    folder_meta = [[],[],[]]\n",
    "if (N_choose_K==2):\n",
    "    folder_iq = [[],[]]\n",
    "    folder_meta = [[],[]]  \n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msps = 25\n",
    "N_choose_K = 2\n",
    "data_IQ_folder_list_test = sorted(pathlib.Path(path_test_25msps_compact).glob('*/'))\n",
    "folder_combo = it.combinations(data_IQ_folder_list_test, N_choose_K) # combinations of all folders\n",
    "combo_tot = scipy.special.comb(10, N_choose_K).astype(int)\n",
    "i = 0\n",
    "j= 0\n",
    "if (N_choose_K==3):\n",
    "    folder_iq = [[],[],[]]\n",
    "    folder_meta = [[],[],[]]\n",
    "if (N_choose_K==2):\n",
    "    folder_iq = [[],[]]\n",
    "    folder_meta = [[],[]]  \n",
    "total_ground_truth_count = 0\n",
    "for x in folder_combo: # start of 1 combination of folders\n",
    "    print('***************************** Start of combined file test *************************************')\n",
    "#     print('folders = ', x)\n",
    "    i = 0\n",
    "    for y in x: # Cycle through all combinations of data files per particular folder combination\n",
    "        print('individual folder = ', y)\n",
    "        folder_iq[i] = sorted(pathlib.Path(y).rglob('*.sigmf-data'))\n",
    "#         folder_meta[i] = sorted(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        folder_meta[i] = list(pathlib.Path(y).rglob('*.sigmf-meta'))\n",
    "        i = i+1\n",
    "    labels = multiclass_test(folder_meta)\n",
    "    combo = [y for y in it.product(*folder_iq)]\n",
    "#     print('combo length = ', len(combo))\n",
    "    for trial in combo:\n",
    "        print('Test iteration = ', j)\n",
    "        j = j+1\n",
    "        center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "#         data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "        results_count = testing_live(center_freq_file, trial, labels, load_net)\n",
    "        total_ground_truth_count = total_ground_truth_count+results_count\n",
    "        # testing_file(msps)\n",
    "        torch.cuda.empty_cache() \n",
    "print('*************************************************************************')\n",
    "print('Total test set percent count = {:.2f}%'.format((total_ground_truth_count/combo_tot)*100))\n",
    "print('*************************************************************************')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iq_read_test_live_combine(combo_list_10msps,msps) # 20211025\n",
    "print('iq data shape = ', data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(path_plot_fig)\n",
    "# temp = np.load('resnet50_acc_plot2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ymin = 70\n",
    "# ymax = 100\n",
    "# axes = plt.gca()\n",
    "# # axes.set_xlim([xmin,xmax])\n",
    "# axes.set_ylim([ymin,ymax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(path_fig)\n",
    "# plt.figure(figsize=(9, 6))\n",
    "# fig = plt.figure()\n",
    "# plt.plot(total_plot[:20],c='r', label='Total patches correct')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Total % correct vs batches')\n",
    "# plt.xlabel('Batch number')\n",
    "# plt.ylabel('% correct')\n",
    "# plt.grid()\n",
    "# fig.savefig('RF_class_resnet50_4D.pdf', format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.chdir(path_fig)\n",
    "# plt.figure(figsize=(9, 6))\n",
    "# fig = plt.figure()\n",
    "# plt.plot(loss_plot,c='r', label='Loss curve')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Loss vs Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid()\n",
    "# fig.savefig('RF_class_v56_loss_4D.pdf', format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = 'ResNet50_multiclass_20220210_mix_autosave_GPU1_2class_train-epoch-19-batch-56000.pt'\n",
    "PATH = path_save+rf_model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr= 1e-4\n",
    "model = resnet50(4,12)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "device = torch.device(cuda)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = 'ResNet50_multiclass_20220201_mix_autosave_GPU1_1class_train-epoch-3-batch-17000_score'\n",
    "PATH = path_save+rf_model\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_net = 'ResNet18_multiclass_20220226_mix_autosave_GPU1_1class_inference-epoch-7-batch-42000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing from saved recording data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIVE inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_net = 'ResNet50_multiclass_20210914_score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# msps = 10\n",
    "# center_freq_live = 433.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_25to10.py\n",
    "# # !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# # usrp_data_collect_1MSPS()\n",
    "# data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "# testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# # testing_live(msps, load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1msps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# updating 20210611 memory saving, STFT stays on GPU\n",
    "msps = 1\n",
    "center_freq_live = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_25to1.py # decimated sampler\n",
    "!python3 /home/david/sigMF_ML/gnuradio/record_live_1msps.py #**********************************************\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# usrp_data_collect_1MSPS()\n",
    "data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "testing_live2(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_live(msps, load_net)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old call\n",
    "# msps = 1\n",
    "# center_freq_live = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_1msps.py\n",
    "# # !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# # usrp_data_collect_1MSPS()\n",
    "# data_IQ_list_val, meta_list_val = inference_read_old(msps)\n",
    "# testing_live_original(msps, load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 msps rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 5\n",
    "center_freq_live = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "!python3 /home/david/sigMF_ML/gnuradio/record_live_5msps.py\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# usrp_data_collect_1MSPS()\n",
    "data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "testing_live2(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# msps = 5\n",
    "# center_freq_live = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_25to5.py\n",
    "# # !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# # usrp_data_collect_1MSPS()\n",
    "# data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "# testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 msps rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 10\n",
    "center_freq_live = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "!python3 /home/david/sigMF_ML/gnuradio/record_live_10msps.py\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# usrp_data_collect_1MSPS()\n",
    "data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "testing_live2(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# msps = 10\n",
    "# center_freq_live = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_25to10.py\n",
    "# # !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# # usrp_data_collect_1MSPS()\n",
    "# data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "# testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25msps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 25\n",
    "center_freq_live = 428.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "!python3 /home/david/sigMF_ML/gnuradio/record_live_25msps.py #***********************************************\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live1msps.py\n",
    "# usrp_data_collect_1MSPS()\n",
    "data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "testing_live2(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING Live sample rate differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_net = 'ResNet50_20210415_scoring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "msps = 1\n",
    "center_freq_live = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# try 25msps decimation to 1msps\n",
    "!python3 /home/david/sigMF_ML/gnuradio/record_live_25to1.py\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_1msps.py\n",
    "# usrp_data_collect_1MSPS()\n",
    "data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "testing_live(msps, load_net)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# msps = 1\n",
    "# center_freq_live = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# # !python3 /home/david/sigMF_ML/gnuradio/record_live_25to1.py\n",
    "# !python3 /home/david/sigMF_ML/gnuradio/record_live_1msps.py\n",
    "# # usrp_data_collect_1MSPS()\n",
    "# data_IQ_list_val, meta_list_val = inference_read(msps)\n",
    "# testing_live(msps,load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing pre-recorded files in /home/david/sigMF_ML/RF/RF_class/testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# msps = 5\n",
    "# center_freq_file = 433.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_5msps)\n",
    "# testing_file(msps)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# msps = 25\n",
    "# center_freq_file = 428.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "# data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_25msps)\n",
    "# testing_live(msps,load_net)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1MSPS combined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 1\n",
    "center_freq_file = 433.65e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_1msps)\n",
    "testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_file(msps)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5MSPS combined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 5\n",
    "center_freq_file = 433.0e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_5msps)\n",
    "testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_file(msps)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10MSPS combined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 10\n",
    "center_freq_file = 433.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_10msps)\n",
    "testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_file(msps)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25MSPS combined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 25\n",
    "center_freq_file = 428.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_25msps)\n",
    "testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_file(msps)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msps = 25\n",
    "center_freq_file = 428.00e6 # when SDR doing 25MSPS with center at 428MHz, or 433.65e6, 428.00e6\n",
    "data_IQ_list_val, meta_list_val = inference_read_file(msps, path_test_25msps)\n",
    "testing_live(center_freq_file, data_IQ_list_val, meta_list_val, load_net)\n",
    "# testing_file(msps)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and Load model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = 'ResNet50_v56_20210208_4D_20dB_autosave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = path_save+rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "# model = resnet50(4, 12)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE MODEL\n",
    "# os.chdir(path_save)\n",
    "# torch.save({\n",
    "#            'epoch': epoch,\n",
    "#            'model_state_dict': model.state_dict(),\n",
    "#            'optimizer_state_dict': optimizer.state_dict(),\n",
    "#            'loss': loss,\n",
    "#            }, path_save+rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD MODEL\n",
    "# checkpoint = torch.load(path_save+rf_model, map_location=device)\n",
    "\n",
    "\n",
    "# # STATUS\n",
    "# checkpoint.keys()\n",
    "\n",
    "# epoch = checkpoint['epoch']\n",
    "# model_state_dict = checkpoint['model_state_dict']\n",
    "# optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# optimizer_state_dict.keys()\n",
    "\n",
    "# optimizer_state_dict['param_groups']\n",
    "\n",
    "# loss\n",
    "\n",
    "# model.load_state_dict(model_state_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "E533 HW1 rev4.ipynb",
   "provenance": [
    {
     "file_id": "1DEqxXQe7Yw25roekLHtUmU_55IJKGY0H",
     "timestamp": 1548894460827
    },
    {
     "file_id": "19e_Vg1krlpJa5zSISQDOVQTwYKepXKql",
     "timestamp": 1548892687570
    },
    {
     "file_id": "1b7T-jkKgv4ynQ_Pe5HCAUM9GTox9fKS9",
     "timestamp": 1548440177000
    },
    {
     "file_id": "12fap5WLhwheizCF9I9Ul-qc2bQ7ZmiWS",
     "timestamp": 1548439576387
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
